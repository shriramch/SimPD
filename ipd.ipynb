{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirpath(path):\n",
    "    dirpath = os.path.dirname(path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a typical Prisoner's Dilemma payoff matrix\n",
    "TYPICAL_PAYOFF_MATRIX = {\n",
    "    \"C\": {\"C\": (3, 3), \"D\": (0, 5)},\n",
    "    \"D\": {\"C\": (5, 0), \"D\": (1, 1)},\n",
    "}\n",
    "\n",
    "NEGATIVE_PAYOFF_MATRIX = {\n",
    "    \"C\": {\"C\": ( 5,  5), \"D\": (-2, 12)},\n",
    "    \"D\": {\"C\": (12, -2), \"D\": ( 0,  0)},\n",
    "}\n",
    "\n",
    "PAYOFF_MATRIX_FOR_ADAPTIVE = {\n",
    "    \"C\": {\"C\": (5, 5), \"D\": (-2, 3)},\n",
    "    \"D\": {\"C\": (3, -2), \"D\": (1, 1)},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract Class for Strategy.\n",
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def move(self, own_history):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListRepeatedStrategy(Strategy):\n",
    "    def __init__(self, moves=[\"C\", \"C\", \"D\"]):\n",
    "        self.moves = moves\n",
    "        self.current_index = 0\n",
    "\n",
    "    def move(self, own_history):\n",
    "        move = self.moves[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.moves)\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naively faithful player (always chooses C)\n",
    "class AlwaysCooperateStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = \"C\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always chooses D\n",
    "class AlwaysDefectStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = \"D\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternating choices between C and D\n",
    "class AlternatingStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        if not own_history or own_history[-1] == \"D\":\n",
    "            move = \"C\"\n",
    "        else:\n",
    "            move = \"D\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = random.choice([\"C\", \"D\"])\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeadStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Switchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategySwitcher(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def check(self, agent, opponent):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOPSwitcher(StrategySwitcher):\n",
    "    def check(self, agent, opponent):\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UseMostCommonNeighborStrategy(StrategySwitcher):\n",
    "#     def check(self, agent, opponent):\n",
    "#         neighbor_strategies = [\n",
    "#             neighbor.strategy.__class__ for neighbor in agent.neighbors\n",
    "#         ]\n",
    "\n",
    "#         strategy_counts = {}\n",
    "#         for strategy in neighbor_strategies:\n",
    "#             strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "\n",
    "#         most_frequent_strategy = max(strategy_counts, key=strategy_counts.get)\n",
    "\n",
    "#         if DEBUG:\n",
    "#             print(\"Whole list: \", neighbor_strategies)\n",
    "#             print(\"Most frequent: \", most_frequent_strategy)\n",
    "\n",
    "#         # Dynamically instantiate the class based on the most frequent string\n",
    "#         try:\n",
    "#             return True, most_frequent_strategy()\n",
    "#         except NameError:\n",
    "#             print(\"Something wrong with my neighbors!\")\n",
    "#             return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMajor(StrategySwitcher):\n",
    "    def check(self, agent, opponent, threshold=0.5):\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        opponent_tally = agent.gather_opponent_tally(opponent)\n",
    "        opponent_cooperation_rate = opponent_tally.get_cooperation_rate()\n",
    "\n",
    "        if opponent_cooperation_rate > threshold and agent.strategy.__class__.__name__ != \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "        elif opponent_cooperation_rate < threshold and agent.strategy.__class__.__name__ != \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveSwitcher(StrategySwitcher):\n",
    "    def __init__(self, payoff_matrix, **kwargs):\n",
    "        self.payoff_matrix = payoff_matrix\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        opponent_tally = agent.gather_opponent_tally(opponent)\n",
    "        opponent_cooperation_rate = opponent_tally.get_cooperation_rate()\n",
    "\n",
    "        reward_C = opponent_cooperation_rate * self.payoff_matrix[\"C\"][\"C\"][0] + (1 - opponent_cooperation_rate) * self.payoff_matrix[\"C\"][\"D\"][0]\n",
    "        reward_D = opponent_cooperation_rate * self.payoff_matrix[\"D\"][\"C\"][0] + (1 - opponent_cooperation_rate) * self.payoff_matrix[\"D\"][\"D\"][0]\n",
    "\n",
    "        if reward_C > reward_D and agent.strategy.__class__.__name__ != \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "        elif reward_C < reward_D and agent.strategy.__class__.__name__ != \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSwitcher(StrategySwitcher):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pool_of_Strats = Strategy.__subclasses__()\n",
    "        self.pool_of_strats.remove(DeadStrategy)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        return True, random.choice(self.pool_of_strats)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitForTat(StrategySwitcher):\n",
    "    def check(self, agent, opponent):\n",
    "        # opponent_history = opponent.history\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "        if DEBUG:\n",
    "            print(\n",
    "                f\"Agent {agent.id} has strategy {agent.strategy.__class__.__name__} and switcher {self.__class__.__name__}\"\n",
    "            )\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "\n",
    "        if (\n",
    "            opponent_history\n",
    "            and opponent_history[-1] == \"D\"\n",
    "            and agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\"\n",
    "        ):\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        elif (\n",
    "            opponent_history\n",
    "            and opponent_history[-1] == \"C\"\n",
    "            and agent.strategy.__class__.__name__ == \"AlwaysDefectStrategy\"\n",
    "        ):\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperateUntilNDefectionsInARow(StrategySwitcher):\n",
    "    def __init__(self, n_defections_threshold=2, **kwargs):\n",
    "        if DEBUG:\n",
    "            print(f\"Initting CooperateUntilNDefectionsInARow with {n_defections_threshold}\")\n",
    "        self.n_defections_threshold = n_defections_threshold\n",
    "        self.n_defections_in_a_row = 0\n",
    "        self.threshold_hit = False\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "        if DEBUG:\n",
    "            print(f\"CooperateUntilNDefections: Checking if should switch for agent {agent.id}\")\n",
    "            print(f\"\\tGot opponent history {opponent_history}\")\n",
    "\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        assert self.n_defections_in_a_row >= 0\n",
    "\n",
    "        if opponent_history and opponent_history[-1] == \"D\":\n",
    "            if DEBUG:\n",
    "                print(\"Increasing defections in a row\")\n",
    "            self.n_defections_in_a_row += 1\n",
    "        else:\n",
    "            self.n_defections_in_a_row = 0\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\n",
    "                f\"Have seen {self.n_defections_in_a_row} defections in a row. Threshold is {self.n_defections_threshold}\"\n",
    "            )\n",
    "        if not self.threshold_hit and self.n_defections_in_a_row >= self.n_defections_threshold:\n",
    "            if DEBUG:\n",
    "                print(\"Threshold hit!\")\n",
    "            self.threshold_hit = True\n",
    "\n",
    "        if agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\" and self.threshold_hit:\n",
    "            if DEBUG:\n",
    "                print(\"Switching to AlwaysDefect\")\n",
    "            return True, AlwaysDefectStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetaliateWithTwoDefections(StrategySwitcher):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.retaliations_left = 0\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        # opponent_history = opponent.history\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        assert self.retaliations_left >= 0\n",
    "\n",
    "        if self.retaliations_left > 0:\n",
    "            self.retaliations_left -= 1\n",
    "\n",
    "        if opponent_history and opponent_history[-1] == \"D\":\n",
    "            self.retaliations_left += 2\n",
    "\n",
    "        if self.retaliations_left > 0 and agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        elif self.retaliations_left == 0 and agent.strategy.__class__.__name__ == \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlayerMoveTally:\n",
    "    cooperations: int = 0\n",
    "    defections: int = 0\n",
    "\n",
    "    def update(self, move):\n",
    "        if move == \"C\":\n",
    "            self.cooperations += 1\n",
    "        elif move == \"D\":\n",
    "            self.defections += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Move must be either 'C' or 'D', got {move}\")\n",
    "\n",
    "    def get_cooperation_rate(self):\n",
    "        # Assume the best in people\n",
    "        if self.cooperations + self.defections == 0:\n",
    "            return 1\n",
    "\n",
    "        return self.cooperations / (self.cooperations + self.defections)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return PlayerMoveTally(\n",
    "            cooperations=self.cooperations + other.cooperations,\n",
    "            defections=self.defections + other.defections,\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Cooperations: {self.cooperations}, Defections: {self.defections}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic class for any Player (next block we shall define inherited classes with specific strategies)\n",
    "class Player:\n",
    "    def __init__(self, strategy, strategy_switcher, credit=0, neighbors=[]):\n",
    "        self.history = []\n",
    "        self.strategy = strategy\n",
    "        self.strategy_switcher = strategy_switcher\n",
    "        self.neighbors = []\n",
    "        self.neighbor_tallies = {}\n",
    "        self.neighbor_histories = {}\n",
    "        self.credit = credit\n",
    "\n",
    "        self.add_neighbors(neighbors)\n",
    "\n",
    "    def add_neighbors(self, neighbors):\n",
    "        assert isinstance(neighbors, list), f\"Expected a list of neighbors, got {type(neighbors)}\"\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in self.neighbors:\n",
    "                self.neighbors.append(neighbor)\n",
    "                self.neighbor_tallies[neighbor.id] = PlayerMoveTally()\n",
    "                self.neighbor_histories[neighbor.id] = []\n",
    "\n",
    "    def set_credit(self, credit):\n",
    "        self.credit = credit\n",
    "\n",
    "    def gather_opponent_tally(self, opponent):\n",
    "        opponent_tally = self.neighbor_tallies.get(opponent.id, PlayerMoveTally())\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"Player {self.id} gathering opponent tally for {opponent.id}\")\n",
    "            print(f\"Knows '{opponent_tally}' so far\")\n",
    "\n",
    "        for neighbor in self.neighbors:\n",
    "            if neighbor.id == opponent.id:\n",
    "                continue\n",
    "\n",
    "            neighbor_info = neighbor.neighbor_tallies.get(opponent.id, PlayerMoveTally())\n",
    "            opponent_tally += neighbor_info\n",
    "\n",
    "            if DEBUG:\n",
    "                print(f\"\\tGot '{neighbor_info}' from {neighbor.id}\")\n",
    "                print(f\"\\tUpdated tally to '{opponent_tally}'\")\n",
    "\n",
    "        return opponent_tally\n",
    "\n",
    "    def update_tally(self, opponent, opponent_move):\n",
    "        self.neighbor_tallies[opponent.id].update(opponent_move)\n",
    "        self.neighbor_histories[opponent.id].append(opponent_move)\n",
    "\n",
    "    def check_should_switch_strategy(self, opponent):\n",
    "        should_switch_strategy, next_strategy = self.strategy_switcher.check(self, opponent)\n",
    "        if should_switch_strategy:\n",
    "            if DEBUG:\n",
    "                print(f\"Agent {self.id} switching strategy to {next_strategy.__class__.__name__}\")\n",
    "            self._switch_strategy(next_strategy)\n",
    "\n",
    "    def play(self, opponent):\n",
    "        decision = self.strategy.move(self.history)\n",
    "        self.update_history(decision)\n",
    "        return decision\n",
    "\n",
    "    def update_history(self, own_move):\n",
    "        self.history.append(own_move)\n",
    "\n",
    "    def update_credit(self, addend):\n",
    "        self.credit += addend\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} credit is now {self.credit}\")\n",
    "        if self.is_dead():\n",
    "            self.strategy = DeadStrategy()\n",
    "\n",
    "    def is_dead(self):\n",
    "        result = self.credit < 0\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} is dead: {result}\")\n",
    "        return result\n",
    "\n",
    "    def check_credit(self):\n",
    "        return self.credit\n",
    "\n",
    "    def latest_move(self):\n",
    "        return self.history[-1]\n",
    "\n",
    "    def _switch_strategy(self, new_strategy):\n",
    "        self.strategy = new_strategy\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} now has switched to strategy {self.strategy.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Edge:\n",
    "    x1: int\n",
    "    y1: int\n",
    "    x2: int\n",
    "    y2: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_indices(cls, index1, index2, width):\n",
    "        x1, y1 = index1 // width, index1 % width\n",
    "        x2, y2 = index2 // width, index2 % width\n",
    "        return cls(x1, y1, x2, y2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.x1}, {self.y1}) -> ({self.x2}, {self.y2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NetworkPosition:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_index(cls, index, width):\n",
    "        return cls(index // width, index % width)\n",
    "\n",
    "    def to_index(self, width):\n",
    "        return self.x * width + self.y\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.x}, {self.y})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, N, M, Ntype=\"Lattice\", density=0, spread=0):\n",
    "        assert Ntype in [\"Graph\", \"Lattice\", \"CLattice\"]\n",
    "        self.dim = (N, M)\n",
    "        self.sz = N * M\n",
    "        self.type = Ntype\n",
    "        self.density = density\n",
    "        self.spread = spread\n",
    "\n",
    "    def generate(self):\n",
    "        self.l = [[0 for _ in range(self.sz)] for _ in range(self.sz)]\n",
    "        self.edges = []\n",
    "\n",
    "        if self.type == \"Graph\":\n",
    "            e = int((self.sz * self.sz - self.sz) * self.density / 2)\n",
    "            assert e > 0\n",
    "\n",
    "            random.seed(int(self.sz * e / 4))\n",
    "\n",
    "            cnt = 0\n",
    "            while cnt < e:\n",
    "                edj = random.randrange(0, self.sz * self.sz)\n",
    "                u, v = edj % self.sz, edj // self.sz\n",
    "                if u == v or self.l[u][v] > 0:\n",
    "                    continue\n",
    "                self.l[u][v] = self.l[v][u] = 1\n",
    "                cnt = cnt + 1\n",
    "\n",
    "        elif self.type == \"Lattice\":\n",
    "            for i in range(0, self.dim[0]):\n",
    "                for j in range(0, self.dim[1]):\n",
    "                    if i > 0:\n",
    "                        self.l[i * self.dim[1] + j][(i - 1) * self.dim[1] + j] = 1\n",
    "                    if i < self.dim[0] - 1:\n",
    "                        self.l[i * self.dim[1] + j][(i + 1) * self.dim[1] + j] = 1\n",
    "                    if j > 0:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j - 1] = 1\n",
    "                    if j < self.dim[1] - 1:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j + 1] = 1\n",
    "\n",
    "        elif self.type == \"CLattice\":\n",
    "            for i in range(0, self.dim[0]):\n",
    "                for j in range(0, self.dim[1]):\n",
    "                    if i > 0:\n",
    "                        self.l[i * self.dim[1] + j][(i - 1) * self.dim[1] + j] = 1\n",
    "                    if i < self.dim[0] - 1:\n",
    "                        self.l[i * self.dim[1] + j][(i + 1) * self.dim[1] + j] = 1\n",
    "                    if j > 0:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j - 1] = 1\n",
    "                    if j < self.dim[1] - 1:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j + 1] = 1\n",
    "\n",
    "            e = int((self.sz * self.sz - self.sz) * self.density / 2)\n",
    "            assert e > 0\n",
    "\n",
    "            random.seed(int(self.sz * e / 4))\n",
    "\n",
    "            cnt = 0\n",
    "            while cnt < e:\n",
    "                edj1 = random.randrange(0, self.sz)\n",
    "                u1, v1 = edj1 // self.dim[1], edj1 % self.dim[1]\n",
    "                u2, v2 = round(random.gauss(u1, self.spread)), round(random.gauss(v1, self.spread))\n",
    "                if (u1 == u2 and v1 == v2) or u2 < 0 or u2 >= self.dim[0] or v2 < 0 or v2 >= self.dim[1]:\n",
    "                    continue\n",
    "                edj2 = u2 * self.dim[1] + v2\n",
    "                if self.l[edj1][edj2] > 0:\n",
    "                    continue\n",
    "                self.l[edj1][edj2] = self.l[edj2][edj1] = 1\n",
    "                cnt = cnt + 1\n",
    "\n",
    "        for i in range(self.sz):\n",
    "            for j in range(i + 1, self.sz):\n",
    "                if self.l[i][j]:\n",
    "                    self.edges.append(Edge.from_indices(i, j, self.dim[1]))\n",
    "\n",
    "        self.E = len(self.edges)\n",
    "\n",
    "    def getEdges(self, from_position):\n",
    "        eList = []\n",
    "        for v in range(0, self.sz):\n",
    "            if self.l[from_position.to_index(self.dim[1])][v] == 1:\n",
    "                eList.append(NetworkPosition.from_index(v, self.dim[1]))\n",
    "\n",
    "        return eList\n",
    "\n",
    "    def printNet(self):\n",
    "        print(\"|V| = \" + str(self.sz) + \"; |E| = \" + str(self.E))\n",
    "        for u in range(self.sz):\n",
    "            at = NetworkPosition.from_index(u, self.dim[1])\n",
    "            print(f\"{at}: \", end=\"\")\n",
    "            lst = self.getEdges(at)\n",
    "            for network_position in lst:\n",
    "                print(f\" {network_position}\", end=\"\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Network(5, 5, \"Lattice\")\n",
    "net1.generate()\n",
    "# net1.printNet()\n",
    "assert net1.E == 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Network(5, 5, \"Graph\", density=0.25)\n",
    "net2.generate()\n",
    "# net2.printNet()\n",
    "assert net2.E == 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = Network(5, 5, \"CLattice\", density=0.04, spread=5)\n",
    "net3.generate()\n",
    "# net3.printNet()\n",
    "assert net3.E == 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorPlayer(Player):\n",
    "    next_id = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = SimulatorPlayer.next_id\n",
    "        SimulatorPlayer.next_id += 1\n",
    "        super().__init__(None, None)\n",
    "\n",
    "    def init(self, neighbors, player):\n",
    "        if DEBUG:\n",
    "            print(f\"Initializing player {self.id}\")\n",
    "\n",
    "        self.add_neighbors(neighbors)\n",
    "        self.history = player.history\n",
    "        self.strategy = player.strategy\n",
    "        self.strategy_switcher = player.strategy_switcher\n",
    "        self.set_credit(player.credit)\n",
    "\n",
    "    def play(self, opponent):\n",
    "        return super().play(opponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, n, m, pm):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.payoff_matrix = pm\n",
    "        self.population = []\n",
    "        self.cooperation_percentage = []\n",
    "        self.status_matrix = [\n",
    "            [False for _ in range(m)] for _ in range(n)\n",
    "        ]  # to store if self.grid[i,j] is dead or alive\n",
    "\n",
    "    def init_network(self, ntype=\"Lattice\", density=0.0, spread=0.0):\n",
    "        self.network = Network(self.n, self.m, ntype, density, spread)\n",
    "        self.network.generate()\n",
    "\n",
    "    def init_grid(self):\n",
    "        self.grid = []\n",
    "        for i in range(self.n):\n",
    "            self.grid.append([])\n",
    "            for j in range(self.m):\n",
    "                self.grid[i].append(SimulatorPlayer())\n",
    "        self.pairs = [(self.grid[edge.x1][edge.y1], self.grid[edge.x2][edge.y2]) for edge in self.network.edges]\n",
    "\n",
    "    def set_player(self, i, j, player):\n",
    "        ngbr_list = self.network.getEdges(NetworkPosition(i, j))\n",
    "        ngbrs = [self.grid[network_position.x][network_position.y] for network_position in ngbr_list]\n",
    "        self.grid[i][j].init(ngbrs, player)\n",
    "\n",
    "    def match(self, p1: SimulatorPlayer, p2: SimulatorPlayer):\n",
    "        if p1.is_dead() or p2.is_dead():\n",
    "            if DEBUG:\n",
    "                print(f\"P1 is dead: {p1.is_dead()}, P2 is dead: {p2.is_dead()}\")\n",
    "            return None\n",
    "        move1 = p1.play(p2)\n",
    "        move2 = p2.play(p1)\n",
    "\n",
    "        p1.update_tally(p2, move2)\n",
    "        p2.update_tally(p1, move1)\n",
    "\n",
    "        p1.check_should_switch_strategy(p2)\n",
    "        p2.check_should_switch_strategy(p1)\n",
    "\n",
    "        score1, score2 = self.payoff_matrix[move1][move2]\n",
    "\n",
    "        p1.update_credit(score1)\n",
    "        p2.update_credit(score2)\n",
    "\n",
    "        return score1, score2\n",
    "\n",
    "    def round(self):\n",
    "        scores = [[0 for _ in range(self.m)] for _ in range(self.n)]\n",
    "        pair_indices = list(range(len(self.pairs)))\n",
    "        random.shuffle(pair_indices)\n",
    "        for i in pair_indices:\n",
    "            pair = self.pairs[i]\n",
    "            edge = self.network.edges[i]\n",
    "            match_scores = self.match(pair[0], pair[1])\n",
    "            if match_scores is None:\n",
    "                continue\n",
    "            score1, score2 = match_scores\n",
    "            scores[edge.x1][edge.y1] += score1\n",
    "            scores[edge.x2][edge.y2] += score2\n",
    "        return scores\n",
    "\n",
    "    def simulate(self, n_rounds=1, ask_status=False, ask_credits=False):\n",
    "        scores_history = []\n",
    "        status_matrices = []\n",
    "        status_matrices.append(copy.deepcopy(self.status_matrix))\n",
    "        credit_matrices = np.zeros((n_rounds, self.m, self.n))\n",
    "        for _ in range(n_rounds):\n",
    "            scores = self.round()\n",
    "            scores_history.append(scores)\n",
    "            self.population.append(self.count_strategies())\n",
    "            self.update_status()\n",
    "            status_matrices.append(copy.deepcopy(self.status_matrix))\n",
    "            # TODO: This should have looped over self.n first since that's what we do everywhere...\n",
    "            for i in range(self.m):\n",
    "                for j in range(self.n):\n",
    "                    # Here we need to flip the indices of grid because we are looping over self.m first\n",
    "                    credit_matrices[_][i][j] = self.grid[j][i].check_credit()\n",
    "\n",
    "        if ask_status:\n",
    "            return status_matrices, scores_history\n",
    "        elif ask_credits:\n",
    "            return credit_matrices\n",
    "        else:\n",
    "            return scores_history\n",
    "\n",
    "    def count_strategies(self, strategy_classes=Strategy.__subclasses__()):\n",
    "        strategy_counts = {name: 0 for name in [cls.__name__ for cls in strategy_classes]}\n",
    "\n",
    "        # TODO: Rewrite this\n",
    "        agents = [agent for grid_line in self.grid for agent in grid_line]\n",
    "        for agent in agents:\n",
    "            for strategy_class in strategy_classes:\n",
    "                if isinstance(agent.strategy, strategy_class):\n",
    "                    strategy_counts[strategy_class.__name__] += 1\n",
    "                    break\n",
    "\n",
    "        return strategy_counts\n",
    "\n",
    "    # New function, to update status_matrix\n",
    "    def update_status(self):\n",
    "        # Update the status of each element in the matrix\n",
    "        for i in range(len(self.status_matrix)):\n",
    "            for j in range(len(self.status_matrix[i])):\n",
    "                self.status_matrix[i][j] = self.grid[i][j].is_dead()\n",
    "\n",
    "    def update_cooperation_rate(self, n_rounds):\n",
    "        for round in range(n_rounds):\n",
    "            round_strings = []\n",
    "\n",
    "            for i in range(self.n):\n",
    "                for j in range(self.m):\n",
    "                    d = len(self.grid[i][j].history) / n_rounds\n",
    "                    start = int(round * d)\n",
    "                    end = int(start + d)\n",
    "                    player_string = self.grid[i][j].history[start:end]\n",
    "                    round_strings += player_string\n",
    "\n",
    "            self.cooperation_percentage.append(round_strings)\n",
    "\n",
    "    def plot_cooperation(self, n_rounds, save_path=None, no_plot=False):\n",
    "        self.update_cooperation_rate(n_rounds)\n",
    "        # Step 1: Calculate percentages per time step\n",
    "        percentages = []\n",
    "        for sublist in self.cooperation_percentage:\n",
    "            count_C = sublist.count(\"C\")\n",
    "            total_count = len(sublist)\n",
    "            percentage_C = count_C / total_count if total_count > 0 else 0\n",
    "            percentages.append(percentage_C)\n",
    "\n",
    "        if not no_plot:\n",
    "            # Step 2: Plotting\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(percentages)\n",
    "\n",
    "            plt.xlabel(\"Virtual Time (rounds)\")\n",
    "            plt.ylabel(\"Percentage of Cooperation\")\n",
    "            plt.title(\"Percentage of Cooperation Over Time\")\n",
    "            # plt.xticks(range(len(self.cooperation_percentage)))\n",
    "            plt.grid(True)\n",
    "\n",
    "            if save_path:\n",
    "                create_dirpath(save_path)\n",
    "                plt.savefig(save_path)\n",
    "\n",
    "            plt.show()\n",
    "        return percentages\n",
    "\n",
    "    def plot_evolution(self, save_path=None):\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(self.population)\n",
    "\n",
    "        # Filter out columns (strategies) where all values are zero\n",
    "        df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for column in df.columns:\n",
    "            plt.plot(df[column], label=column)\n",
    "            # plt.plot(df.index, df[column], marker='o', label=column)\n",
    "\n",
    "        plt.xlabel(\"Virtual Time (rounds)\")\n",
    "        plt.ylabel(\"Strategy Value\")\n",
    "        plt.title(\"Evolution of Strategies Over Time\")\n",
    "        # plt.xticks(range(len(df)))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        if save_path:\n",
    "            create_dirpath(save_path)\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "        plt.show()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_of_strats = Strategy.__subclasses__()\n",
    "pool_of_strats.remove(DeadStrategy)\n",
    "# NOTE: Some StrategySwitchers have default parameters we could play around with.\n",
    "pool_of_switchers = StrategySwitcher.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "\n",
    "50-50 AllC and AllD strats randomly distributed. AllD players have SoftMajor switcher, AllC players have a random chance $p$ of having NOPSiwtcher.\n",
    "\n",
    "Result: for $p >= 0.1$, all players eventually adopt AllC strategy.\n",
    "\n",
    "Interpretation: small number of pure cooperative players lead to stable cooperation starting from symmetry 50-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment scale\n",
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "insist_percent = np.arange(0, 1 + 0.01, 0.05)\n",
    "cooperate_dominance = np.zeros(len(insist_percent))\n",
    "for k, p in enumerate(insist_percent):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            if chosen_strategy == AlwaysCooperateStrategy and random.random() < p:\n",
    "                chosen_switcher = NOPSwitcher\n",
    "            else:\n",
    "                chosen_switcher = SoftMajor\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher()))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment1/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment1/evolution.png\")\n",
    "\n",
    "plt.plot(insist_percent, cooperate_dominance)\n",
    "plt.xlabel(\"Percentage of pure Cooperative Players\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.title(\"Small number of pure cooperative players can invade all\")\n",
    "plt.savefig(\"results/experiment1/insist_percent_v_cooperate_dominance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "50-50 AllC and AllD strats randomly distributed. All players have SoftMajor switcher.\n",
    "\n",
    "Result: eventually the numbers of AllC and AllD players saturate, around values around 0.5 (this depends on the distribution) -> so is the cooperation rate.\n",
    "\n",
    "Interpretation: everyone mimics their neighbors will lead to random equilibrium around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 20\n",
    "cooperate_dominance = np.zeros(iterations)  # The percentage of allC in each and every iteration\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            chosen_switcher = SoftMajor\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher()))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment2/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment2/evolution.png\")\n",
    "\n",
    "plt.scatter(np.arange(0, len(cooperate_dominance), 1), cooperate_dominance)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.title(\"SoftMajor leads to random equilibrium around 50-50\")\n",
    "plt.savefig(\"results/experiment2/cooperative_players_at_equilibrium.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_points(grid_size, N):\n",
    "    points = set()\n",
    "\n",
    "    while len(points) < N:\n",
    "        x = random.randint(0, grid_size - 1)\n",
    "        y = random.randint(0, grid_size - 1)\n",
    "        points.add((x, y))\n",
    "\n",
    "    return list(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3a\n",
    "\n",
    "Start with all players cooperating (allC) except a few n_defect random allD. All players adopt CooperateUntilNDefect switcher.\n",
    "\n",
    "Interpretation: A population with cynical meta-strategy (switcher) will lead to instable cooperative behavior: only takes some allD to invade all.\n",
    "\n",
    "Expected result:\n",
    "\n",
    "1) For non-zero n_defect, eventually, most if not all players will be allD\n",
    "2) As we increase n_defect (initial number of allD players), it will take fewer rounds to reach allD population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 20\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "# We sprinkle some AllD randomly on lattice:\n",
    "n_defect = 15\n",
    "AllD_players_list = generate_random_points(grid_size, n_defect)\n",
    "\n",
    "iterations = 1\n",
    "cooperate_dominance = np.zeros(iterations)  # The percentage of allC in each and every iteration\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in AllD_players_list:\n",
    "                chosen_strategy = AlwaysDefectStrategy\n",
    "            else:\n",
    "                chosen_strategy = AlwaysCooperateStrategy\n",
    "            chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "            # TODO: Vary the N\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment3a/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment3a/evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3b\n",
    "We repeat the above setup, but only 1 defective player x, run over many iterations, each with a different location for X. Goal: investigate the effect of X's location on the number of steps needed for cooperation collapse (coop percentage drops below 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 20\n",
    "num_rounds = 50\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "collapse_points = np.zeros((grid_size, grid_size))\n",
    "for m in range(grid_size):\n",
    "    for n in range(grid_size):\n",
    "        current_point = (m, n)\n",
    "        s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "        s.init_network(\"Lattice\")\n",
    "        s.init_grid()\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if (i, j) == current_point:\n",
    "                    chosen_strategy = AlwaysDefectStrategy\n",
    "                else:\n",
    "                    chosen_strategy = AlwaysCooperateStrategy\n",
    "                chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "                # TODO: Vary the N\n",
    "                s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "        s.simulate(n_rounds=num_rounds)\n",
    "        # coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\n",
    "        percentage_list = s.plot_cooperation(num_rounds, no_plot=True)\n",
    "        collapse_step = next((i for i, x in enumerate(percentage_list) if x < 0.1), None)\n",
    "        collapse_points[m][n] = collapse_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.imshow(collapse_points, cmap=\"hot\", interpolation=\"nearest\")\n",
    "\n",
    "# Add a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Defector collapse index\")\n",
    "create_dirpath(\"results/experiment3b/defector_collapse_index.png\")\n",
    "plt.savefig(\"results/experiment3b/defector_collapse_index.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3c\n",
    "We run the setups with various numbers of defects (each with many iterations to average over) to find the number of steps (on average) it takes until cooperation collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 20\n",
    "num_rounds = 30\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "defect_num = [1, 2, 4, 5, 10, 15]\n",
    "collapse_points = np.zeros(len(defect_num))  # array to store average collapse points for different defect_num\n",
    "\n",
    "iteration_num = 20\n",
    "for _, n_defect in enumerate(defect_num):\n",
    "    # to store all collapse_step over iterations to be averaged over\n",
    "    temp_array = np.zeros(iteration_num)\n",
    "    for k in range(iteration_num):\n",
    "        AllD_players_list = generate_random_points(grid_size, n_defect)\n",
    "        s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "        s.init_network(\"Lattice\")\n",
    "        s.init_grid()\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if (i, j) in AllD_players_list:\n",
    "                    chosen_strategy = AlwaysDefectStrategy\n",
    "                else:\n",
    "                    chosen_strategy = AlwaysCooperateStrategy\n",
    "                chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "                # TODO: Vary the N\n",
    "                s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "        s.simulate(n_rounds=num_rounds)\n",
    "        # coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\n",
    "        percentage_list = s.plot_cooperation(num_rounds, no_plot=True)\n",
    "        collapse_step = next((i for i, x in enumerate(percentage_list) if x < 0.1), None)\n",
    "        temp_array[k] = collapse_step\n",
    "\n",
    "    collapse_points[_] = np.mean(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Define the exponential function\n",
    "def exp_decay_func(x, a, b):\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "\n",
    "defect_num = np.array(defect_num)\n",
    "# Perform the curve fitting\n",
    "params, _ = curve_fit(exp_decay_func, defect_num, collapse_points)\n",
    "a, b = params[0], params[1]\n",
    "\n",
    "# Generate a denser set of x-values for the smoother curve\n",
    "x_dense = np.linspace(defect_num.min(), defect_num.max(), 500)\n",
    "\n",
    "# Calculate the fitted y-values for the denser x-values\n",
    "fitted_y_dense = exp_decay_func(x_dense, a, b)\n",
    "\n",
    "# Calculate residuals and the standard deviation\n",
    "residuals = collapse_points - exp_decay_func(defect_num, a, b)\n",
    "std_dev = np.std(residuals)\n",
    "\n",
    "# Create the plot\n",
    "plt.errorbar(defect_num, collapse_points, yerr=std_dev, fmt=\"o\", label=\"Original Data\", ecolor=\"lightgray\", capsize=5)\n",
    "plt.plot(x_dense, fitted_y_dense, label=\"Fitted Exponential Curve\", color=\"red\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Number of defects\")\n",
    "plt.ylabel(\"Average collapse index\")\n",
    "plt.title(\"Average collapse index vs number of defects randomly distributed\")\n",
    "plt.legend()\n",
    "\n",
    "create_dirpath(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "plt.savefig(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: credit system\n",
    "\n",
    "Start with 50-50 allC, allD in terms of strategies. For switchers we pick equal number of each. Give each player the same number of credits initially.\n",
    "\n",
    "1) We plot number of non-debters (survivors) against time to see if some switchers cannot survive.\n",
    "2) Repeat for different pay-off matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that evenly assigns players to switcher types via lattice location\n",
    "# input N: number of switchers\n",
    "# return lookup_table: dictionary to tell which switcher type (i,j) belongs to (outcome indexed by pool_of_switchers)\n",
    "def assign_switchers(grid_size, N):\n",
    "    total_vertices = grid_size**2\n",
    "    approx_size = total_vertices // N\n",
    "    extra = total_vertices % N\n",
    "\n",
    "    vertices_sets = [set() for _ in range(N)]\n",
    "    lookup_table = {}\n",
    "    current_set = 0\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            vertices_sets[current_set].add((i, j))\n",
    "            lookup_table[(i, j)] = current_set\n",
    "            if len(vertices_sets[current_set]) >= approx_size + (current_set < extra):\n",
    "                current_set += 1\n",
    "\n",
    "    return vertices_sets, lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 10\n",
    "CHOSEN_PAYOFF_MATRIX = NEGATIVE_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 1\n",
    "\n",
    "sets, players_switchers = assign_switchers(grid_size, len(pool_of_switchers))\n",
    "\n",
    "init_credit = 15  # initial credit per player\n",
    "\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            chosen_switcher = pool_of_switchers[players_switchers[(i, j)]]\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(payoff_matrix=CHOSEN_PAYOFF_MATRIX), init_credit))\n",
    "\n",
    "    status_matrices, _ = s.simulate(n_rounds=num_rounds, ask_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# visualize dead (blue) or alive (red) at a time step (has 1 element more than number of time steps to account for initial status)\n",
    "def visualize_boolean_matrix(matrix, save_path=None):\n",
    "    # Create a custom colormap for True (black) and False (white)\n",
    "    cmap = mcolors.ListedColormap([\"black\", \"white\"])\n",
    "\n",
    "    # Convert the boolean matrix to integers (True=0, False=1)\n",
    "    int_matrix = np.where(matrix, 0, 1)\n",
    "\n",
    "    # Plot the matrix with the custom colormap\n",
    "    plt.imshow(int_matrix, cmap=cmap, interpolation=\"none\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_path:\n",
    "        create_dirpath(save_path)\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO: Why status_matrices[2]?\n",
    "visualize_boolean_matrix(status_matrices[2], save_path=\"results/experiment4/status_matrices.png\")\n",
    "# print(status_matrices[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that counts dead/alive players of each switcher type for a status_matrix at a time step\n",
    "def count_true_false(status_matrix, lookup, N):\n",
    "    # Initialize counters for each set\n",
    "    counters = {i: {\"True\": 0, \"False\": 0} for i in range(N)}\n",
    "\n",
    "    # Iterate over the status_matrix\n",
    "    for i in range(len(status_matrix)):\n",
    "        for j in range(len(status_matrix[i])):\n",
    "            set_index = lookup[(i, j)]\n",
    "            if status_matrix[i][j]:\n",
    "                counters[set_index][\"True\"] += 1\n",
    "            else:\n",
    "                counters[set_index][\"False\"] += 1\n",
    "\n",
    "    return counters\n",
    "\n",
    "\n",
    "# Function that counts dead/alive players of each switcher type for all time step status_matrix, i.e. status_matrices\n",
    "def compute_counters_for_all_matrices(status_matrices, lookup, N):\n",
    "    all_counters = []\n",
    "    for status_matrix in status_matrices:\n",
    "        counters = count_true_false(status_matrix, lookup, N)\n",
    "        all_counters.append(counters)\n",
    "    return all_counters\n",
    "\n",
    "\n",
    "counters_end = count_true_false(status_matrices[-1], players_switchers, len(pool_of_switchers))\n",
    "counters_beg = count_true_false(status_matrices[0], players_switchers, len(pool_of_switchers))\n",
    "\n",
    "\n",
    "# SOME QUICK CHECK\n",
    "print(\"Current payoff matrix:\")\n",
    "print(CHOSEN_PAYOFF_MATRIX)\n",
    "# Output the counts for each switcher at the beginning and the end\n",
    "print(\"\\nBegin:\")\n",
    "for set_index, counts in counters_beg.items():\n",
    "    print(f\"Switcher {set_index + 1}: Dead = {counts['True']}, Alive = {counts['False']}\")\n",
    "print(\"\\nFinal:\")\n",
    "for set_index, counts in counters_end.items():\n",
    "    print(f\"Switcher {set_index + 1}: Dead = {counts['True']}, Alive = {counts['False']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counters = compute_counters_for_all_matrices(status_matrices, players_switchers, len(pool_of_switchers))\n",
    "\n",
    "# Preparing data for plotting\n",
    "true_counts = {i: [] for i in range(len(pool_of_switchers))}\n",
    "for counters in all_counters:\n",
    "    for set_index in range(len(pool_of_switchers)):\n",
    "        true_counts[set_index].append(counters[set_index][\"True\"])\n",
    "\n",
    "# Plotting\n",
    "for set_index, counts in true_counts.items():\n",
    "    plt.plot(counts, label=str(pool_of_switchers[set_index].__name__))\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Number of Dead Players\")\n",
    "plt.title(\"Dead Players Over Time for Each Switcher\")\n",
    "plt.legend()\n",
    "create_dirpath(\"results/experiment4/dead_players_over_time.png\")\n",
    "plt.savefig(\"results/experiment4/dead_players_over_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5\n",
    "50-50 allC and allD starting out similarly to exp 1. Instead of mimicking their neighbors, players use Bayesian probability based on opponent's history to adapt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment scale\n",
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = PAYOFF_MATRIX_FOR_ADAPTIVE\n",
    "\n",
    "# insist_percent = np.arange(0, 1 + 0.01, 0.05)\n",
    "insist_percent = [0.0]\n",
    "cooperate_dominance = np.zeros(len(insist_percent))\n",
    "for k, p in enumerate(insist_percent):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            if chosen_strategy == AlwaysCooperateStrategy and random.random() < p:\n",
    "                chosen_switcher = NOPSwitcher\n",
    "            else:\n",
    "                chosen_switcher = AdaptiveSwitcher\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(payoff_matrix=CHOSEN_PAYOFF_MATRIX)))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment5/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment5/evolution.png\")\n",
    "\n",
    "plt.plot(insist_percent, cooperate_dominance)\n",
    "plt.xlabel(\"Percentage of pure Cooperative Players\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.savefig(\"results/experiment5/insist_percent_v_cooperate_dominance.png\")\n",
    "plt.title(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing animations\n",
    "create an gif of a grid of credits evolving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 10\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 1\n",
    "\n",
    "sets, players_switchers = assign_switchers(grid_size, len(pool_of_switchers))\n",
    "\n",
    "init_credit = 0  # initial credit per player\n",
    "\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            # chosen_switcher = pool_of_switchers[players_switchers[(i,j)]]\n",
    "            chosen_switcher = NOPSwitcher\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(), init_credit))\n",
    "\n",
    "    credit_matrices = s.simulate(n_rounds=num_rounds, ask_credits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Example data: a simple 3D numpy array\n",
    "# For the sake of example, let's create a 3D array with random data\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Function to update the plot for each frame\n",
    "def update(frame):\n",
    "    mat.set_data(credit_matrices[frame])\n",
    "    return [mat]\n",
    "\n",
    "\n",
    "# Set up the initial plot\n",
    "fig, ax = plt.subplots()\n",
    "mat = ax.matshow(credit_matrices[0], cmap=\"viridis\")\n",
    "plt.colorbar(mat)\n",
    "ax.set_title(\"Credit matrix evolution\")\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=num_rounds, interval=200, blit=True)\n",
    "create_dirpath(\"results/animations/credit_matrix_evolution.gif\")\n",
    "ani.save(\"results/animations/lattice_evolution.gif\", writer=\"pillow\", fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CooperateUntilNDefectionsInARow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cooperate_until_n_defections_in_a_row(threshold_n, repeated_list):\n",
    "    print(f\"Testing CooperateUntilNDefectionsInARow (N = {threshold_n})\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), CooperateUntilNDefectionsInARow(threshold_n)))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    threshold_hit, ds_in_a_row = False, 0\n",
    "    for move in repeated_list:\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            ds_in_a_row += 1\n",
    "        else:\n",
    "            ds_in_a_row = 0\n",
    "\n",
    "        if ds_in_a_row >= threshold_n:\n",
    "            threshold_hit = True\n",
    "\n",
    "        if threshold_hit:\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=1,\n",
    "    repeated_list=[\"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=1,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=2,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=3,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TitForTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tit_for_tat(repeated_list):\n",
    "    print(f\"Testing TitForTat\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), TitForTat()))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    for move in repeated_list:\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tit_for_tat(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\", \"C\", \"C\", \"D\", \"D\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetaliateWithTwoDefections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retaliate_with_two_defections(repeated_list, *, n_retaliations=2):\n",
    "    print(f\"Testing RetaliateWithTwoDefections\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), RetaliateWithTwoDefections()))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    n_defections_left = 0\n",
    "    for move in repeated_list:\n",
    "        assert n_defections_left >= 0\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            n_defections_left += n_retaliations\n",
    "\n",
    "        if n_defections_left > 0:\n",
    "            n_defections_left -= 1\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"C\", \"C\", \"C\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"D\", \"D\", \"C\", \"C\", \"C\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\", \"C\", \"C\", \"D\", \"D\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftMajor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptiveSwitcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
