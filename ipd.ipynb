{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirpath(path):\n",
    "    dirpath = os.path.dirname(path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a typical Prisoner's Dilemma payoff matrix\n",
    "TYPICAL_PAYOFF_MATRIX = {\n",
    "    \"C\": {\"C\": (3, 3), \"D\": (0, 5)},\n",
    "    \"D\": {\"C\": (5, 0), \"D\": (1, 1)},\n",
    "}\n",
    "\n",
    "NEGATIVE_PAYOFF_MATRIX = {\n",
    "    \"C\": {\"C\": ( 5,  5), \"D\": (-2, 12)},\n",
    "    \"D\": {\"C\": (12, -2), \"D\": ( 0,  0)},\n",
    "}\n",
    "\n",
    "PAYOFF_MATRIX_FOR_ADAPTIVE = {\n",
    "    \"C\": {\"C\": (5, 5), \"D\": (-2, 3)},\n",
    "    \"D\": {\"C\": (3, -2), \"D\": (1, 1)},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract Class for Strategy.\n",
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def move(self, own_history):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListRepeatedStrategy(Strategy):\n",
    "    def __init__(self, moves=[\"C\", \"C\", \"D\"]):\n",
    "        self.moves = moves\n",
    "        self.current_index = 0\n",
    "\n",
    "    def move(self, own_history):\n",
    "        move = self.moves[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.moves)\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naively faithful player (always chooses C)\n",
    "class AlwaysCooperateStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = \"C\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always chooses D\n",
    "class AlwaysDefectStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = \"D\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternating choices between C and D\n",
    "class AlternatingStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        if not own_history or own_history[-1] == \"D\":\n",
    "            move = \"C\"\n",
    "        else:\n",
    "            move = \"D\"\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        move = random.choice([\"C\", \"D\"])\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeadStrategy(Strategy):\n",
    "    def move(self, own_history):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Switchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategySwitcher(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def check(self, agent, opponent):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOPSwitcher(StrategySwitcher):\n",
    "    def check(self, agent, opponent):\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UseMostCommonNeighborStrategy(StrategySwitcher):\n",
    "#     def check(self, agent, opponent):\n",
    "#         neighbor_strategies = [\n",
    "#             neighbor.strategy.__class__ for neighbor in agent.neighbors\n",
    "#         ]\n",
    "\n",
    "#         strategy_counts = {}\n",
    "#         for strategy in neighbor_strategies:\n",
    "#             strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "\n",
    "#         most_frequent_strategy = max(strategy_counts, key=strategy_counts.get)\n",
    "\n",
    "#         if DEBUG:\n",
    "#             print(\"Whole list: \", neighbor_strategies)\n",
    "#             print(\"Most frequent: \", most_frequent_strategy)\n",
    "\n",
    "#         # Dynamically instantiate the class based on the most frequent string\n",
    "#         try:\n",
    "#             return True, most_frequent_strategy()\n",
    "#         except NameError:\n",
    "#             print(\"Something wrong with my neighbors!\")\n",
    "#             return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMajor(StrategySwitcher):\n",
    "    def check(self, agent, opponent, threshold=0.5):\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        opponent_tally = agent.gather_opponent_tally(opponent)\n",
    "        opponent_cooperation_rate = opponent_tally.get_cooperation_rate()\n",
    "\n",
    "        if opponent_cooperation_rate > threshold and agent.strategy.__class__.__name__ != \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "        elif opponent_cooperation_rate < threshold and agent.strategy.__class__.__name__ != \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveSwitcher(StrategySwitcher):\n",
    "    def __init__(self, payoff_matrix, **kwargs):\n",
    "        self.payoff_matrix = payoff_matrix\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        opponent_tally = agent.gather_opponent_tally(opponent)\n",
    "        opponent_cooperation_rate = opponent_tally.get_cooperation_rate()\n",
    "\n",
    "        reward_C = opponent_cooperation_rate * self.payoff_matrix[\"C\"][\"C\"][0] + (1 - opponent_cooperation_rate) * self.payoff_matrix[\"C\"][\"D\"][0]\n",
    "        reward_D = opponent_cooperation_rate * self.payoff_matrix[\"D\"][\"C\"][0] + (1 - opponent_cooperation_rate) * self.payoff_matrix[\"D\"][\"D\"][0]\n",
    "\n",
    "        if reward_C > reward_D and agent.strategy.__class__.__name__ != \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "        elif reward_C < reward_D and agent.strategy.__class__.__name__ != \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSwitcher(StrategySwitcher):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pool_of_strats = Strategy.__subclasses__()\n",
    "        self.pool_of_strats.remove(DeadStrategy)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        return True, random.choice(self.pool_of_strats)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitForTat(StrategySwitcher):\n",
    "    def check(self, agent, opponent):\n",
    "        # opponent_history = opponent.history\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "        if DEBUG:\n",
    "            print(\n",
    "                f\"Agent {agent.id} has strategy {agent.strategy.__class__.__name__} and switcher {self.__class__.__name__}\"\n",
    "            )\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "\n",
    "        if (\n",
    "            opponent_history\n",
    "            and opponent_history[-1] == \"D\"\n",
    "            and agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\"\n",
    "        ):\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        elif (\n",
    "            opponent_history\n",
    "            and opponent_history[-1] == \"C\"\n",
    "            and agent.strategy.__class__.__name__ == \"AlwaysDefectStrategy\"\n",
    "        ):\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperateUntilNDefectionsInARow(StrategySwitcher):\n",
    "    def __init__(self, n_defections_threshold=2, **kwargs):\n",
    "        if DEBUG:\n",
    "            print(f\"Initting CooperateUntilNDefectionsInARow with {n_defections_threshold}\")\n",
    "        self.n_defections_threshold = n_defections_threshold\n",
    "        self.n_defections_in_a_row = 0\n",
    "        self.threshold_hit = False\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "        if DEBUG:\n",
    "            print(f\"CooperateUntilNDefections: Checking if should switch for agent {agent.id}\")\n",
    "            print(f\"\\tGot opponent history {opponent_history}\")\n",
    "\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        assert self.n_defections_in_a_row >= 0\n",
    "\n",
    "        if opponent_history and opponent_history[-1] == \"D\":\n",
    "            if DEBUG:\n",
    "                print(\"Increasing defections in a row\")\n",
    "            self.n_defections_in_a_row += 1\n",
    "        else:\n",
    "            self.n_defections_in_a_row = 0\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\n",
    "                f\"Have seen {self.n_defections_in_a_row} defections in a row. Threshold is {self.n_defections_threshold}\"\n",
    "            )\n",
    "        if not self.threshold_hit and self.n_defections_in_a_row >= self.n_defections_threshold:\n",
    "            if DEBUG:\n",
    "                print(\"Threshold hit!\")\n",
    "            self.threshold_hit = True\n",
    "\n",
    "        if agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\" and self.threshold_hit:\n",
    "            if DEBUG:\n",
    "                print(\"Switching to AlwaysDefect\")\n",
    "            return True, AlwaysDefectStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetaliateWithTwoDefections(StrategySwitcher):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.retaliations_left = 0\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def check(self, agent, opponent):\n",
    "        # opponent_history = opponent.history\n",
    "        opponent_history = agent.neighbor_histories[opponent.id]\n",
    "\n",
    "        assert agent.strategy.__class__.__name__ in [\n",
    "            \"AlwaysCooperateStrategy\",\n",
    "            \"AlwaysDefectStrategy\",\n",
    "        ]\n",
    "        assert self.retaliations_left >= 0\n",
    "\n",
    "        if self.retaliations_left > 0:\n",
    "            self.retaliations_left -= 1\n",
    "\n",
    "        if opponent_history and opponent_history[-1] == \"D\":\n",
    "            self.retaliations_left += 2\n",
    "\n",
    "        if self.retaliations_left > 0 and agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "        elif self.retaliations_left == 0 and agent.strategy.__class__.__name__ == \"AlwaysDefectStrategy\":\n",
    "            return True, AlwaysCooperateStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlayerMoveTally:\n",
    "    cooperations: int = 0\n",
    "    defections: int = 0\n",
    "\n",
    "    def update(self, move):\n",
    "        if move == \"C\":\n",
    "            self.cooperations += 1\n",
    "        elif move == \"D\":\n",
    "            self.defections += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Move must be either 'C' or 'D', got {move}\")\n",
    "\n",
    "    def get_cooperation_rate(self):\n",
    "        # Assume the best in people\n",
    "        if self.cooperations + self.defections == 0:\n",
    "            return 1\n",
    "\n",
    "        return self.cooperations / (self.cooperations + self.defections)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return PlayerMoveTally(\n",
    "            cooperations=self.cooperations + other.cooperations,\n",
    "            defections=self.defections + other.defections,\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Cooperations: {self.cooperations}, Defections: {self.defections}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic class for any Player (next block we shall define inherited classes with specific strategies)\n",
    "class Player:\n",
    "    def __init__(self, strategy, strategy_switcher, credit=0, neighbors=[]):\n",
    "        self.history = []\n",
    "        self.strategy = strategy\n",
    "        self.strategy_switcher = strategy_switcher\n",
    "        self.neighbors = []\n",
    "        self.neighbor_tallies = {}\n",
    "        self.neighbor_histories = {}\n",
    "        self.credit = credit\n",
    "\n",
    "        self.add_neighbors(neighbors)\n",
    "\n",
    "    def add_neighbors(self, neighbors):\n",
    "        assert isinstance(neighbors, list), f\"Expected a list of neighbors, got {type(neighbors)}\"\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in self.neighbors:\n",
    "                self.neighbors.append(neighbor)\n",
    "                self.neighbor_tallies[neighbor.id] = PlayerMoveTally()\n",
    "                self.neighbor_histories[neighbor.id] = []\n",
    "\n",
    "    def set_credit(self, credit):\n",
    "        self.credit = credit\n",
    "\n",
    "    def gather_opponent_tally(self, opponent):\n",
    "        opponent_tally = self.neighbor_tallies.get(opponent.id, PlayerMoveTally())\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"Player {self.id} gathering opponent tally for {opponent.id}\")\n",
    "            print(f\"Knows '{opponent_tally}' so far\")\n",
    "\n",
    "        for neighbor in self.neighbors:\n",
    "            if neighbor.id == opponent.id:\n",
    "                continue\n",
    "\n",
    "            neighbor_info = neighbor.neighbor_tallies.get(opponent.id, PlayerMoveTally())\n",
    "            opponent_tally += neighbor_info\n",
    "\n",
    "            if DEBUG:\n",
    "                print(f\"\\tGot '{neighbor_info}' from {neighbor.id}\")\n",
    "                print(f\"\\tUpdated tally to '{opponent_tally}'\")\n",
    "\n",
    "        return opponent_tally\n",
    "\n",
    "    def update_tally(self, opponent, opponent_move):\n",
    "        self.neighbor_tallies[opponent.id].update(opponent_move)\n",
    "        self.neighbor_histories[opponent.id].append(opponent_move)\n",
    "\n",
    "    def check_should_switch_strategy(self, opponent):\n",
    "        should_switch_strategy, next_strategy = self.strategy_switcher.check(self, opponent)\n",
    "        if should_switch_strategy:\n",
    "            if DEBUG:\n",
    "                print(f\"Agent {self.id} switching strategy to {next_strategy.__class__.__name__}\")\n",
    "            self._switch_strategy(next_strategy)\n",
    "\n",
    "    def play(self, opponent):\n",
    "        decision = self.strategy.move(self.history)\n",
    "        self.update_history(decision)\n",
    "        return decision\n",
    "\n",
    "    def update_history(self, own_move):\n",
    "        self.history.append(own_move)\n",
    "\n",
    "    def update_credit(self, addend):\n",
    "        self.credit += addend\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} credit is now {self.credit}\")\n",
    "        if self.is_dead():\n",
    "            self.strategy = DeadStrategy()\n",
    "\n",
    "    def is_dead(self):\n",
    "        result = self.credit < 0\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} is dead: {result}\")\n",
    "        return result\n",
    "\n",
    "    def check_credit(self):\n",
    "        return self.credit\n",
    "\n",
    "    def latest_move(self):\n",
    "        return self.history[-1]\n",
    "\n",
    "    def _switch_strategy(self, new_strategy):\n",
    "        self.strategy = new_strategy\n",
    "        if DEBUG:\n",
    "            print(f\"Agent {self.id} now has switched to strategy {self.strategy.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Edge:\n",
    "    x1: int\n",
    "    y1: int\n",
    "    x2: int\n",
    "    y2: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_indices(cls, index1, index2, width):\n",
    "        x1, y1 = index1 // width, index1 % width\n",
    "        x2, y2 = index2 // width, index2 % width\n",
    "        return cls(x1, y1, x2, y2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.x1}, {self.y1}) -> ({self.x2}, {self.y2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NetworkPosition:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_index(cls, index, width):\n",
    "        return cls(index // width, index % width)\n",
    "\n",
    "    def to_index(self, width):\n",
    "        return self.x * width + self.y\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.x}, {self.y})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, N, M, Ntype=\"Lattice\", density=0, spread=0):\n",
    "        assert Ntype in [\"Graph\", \"Lattice\", \"CLattice\"]\n",
    "        self.dim = (N, M)\n",
    "        self.sz = N * M\n",
    "        self.type = Ntype\n",
    "        self.density = density\n",
    "        self.spread = spread\n",
    "\n",
    "    def generate(self):\n",
    "        self.l = [[0 for _ in range(self.sz)] for _ in range(self.sz)]\n",
    "        self.edges = []\n",
    "\n",
    "        if self.type == \"Graph\":\n",
    "            e = int((self.sz * self.sz - self.sz) * self.density / 2)\n",
    "            assert e > 0\n",
    "\n",
    "            random.seed(int(self.sz * e / 4))\n",
    "\n",
    "            cnt = 0\n",
    "            while cnt < e:\n",
    "                edj = random.randrange(0, self.sz * self.sz)\n",
    "                u, v = edj % self.sz, edj // self.sz\n",
    "                if u == v or self.l[u][v] > 0:\n",
    "                    continue\n",
    "                self.l[u][v] = self.l[v][u] = 1\n",
    "                cnt = cnt + 1\n",
    "\n",
    "        elif self.type == \"Lattice\":\n",
    "            for i in range(0, self.dim[0]):\n",
    "                for j in range(0, self.dim[1]):\n",
    "                    if i > 0:\n",
    "                        self.l[i * self.dim[1] + j][(i - 1) * self.dim[1] + j] = 1\n",
    "                    if i < self.dim[0] - 1:\n",
    "                        self.l[i * self.dim[1] + j][(i + 1) * self.dim[1] + j] = 1\n",
    "                    if j > 0:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j - 1] = 1\n",
    "                    if j < self.dim[1] - 1:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j + 1] = 1\n",
    "\n",
    "        elif self.type == \"CLattice\":\n",
    "            for i in range(0, self.dim[0]):\n",
    "                for j in range(0, self.dim[1]):\n",
    "                    if i > 0:\n",
    "                        self.l[i * self.dim[1] + j][(i - 1) * self.dim[1] + j] = 1\n",
    "                    if i < self.dim[0] - 1:\n",
    "                        self.l[i * self.dim[1] + j][(i + 1) * self.dim[1] + j] = 1\n",
    "                    if j > 0:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j - 1] = 1\n",
    "                    if j < self.dim[1] - 1:\n",
    "                        self.l[i * self.dim[1] + j][i * self.dim[1] + j + 1] = 1\n",
    "\n",
    "            e = int((self.sz * self.sz - self.sz) * self.density / 2)\n",
    "            assert e > 0\n",
    "\n",
    "            random.seed(int(self.sz * e / 4))\n",
    "\n",
    "            cnt = 0\n",
    "            while cnt < e:\n",
    "                edj1 = random.randrange(0, self.sz)\n",
    "                u1, v1 = edj1 // self.dim[1], edj1 % self.dim[1]\n",
    "                u2, v2 = round(random.gauss(u1, self.spread)), round(random.gauss(v1, self.spread))\n",
    "                if (u1 == u2 and v1 == v2) or u2 < 0 or u2 >= self.dim[0] or v2 < 0 or v2 >= self.dim[1]:\n",
    "                    continue\n",
    "                edj2 = u2 * self.dim[1] + v2\n",
    "                if self.l[edj1][edj2] > 0:\n",
    "                    continue\n",
    "                self.l[edj1][edj2] = self.l[edj2][edj1] = 1\n",
    "                cnt = cnt + 1\n",
    "\n",
    "        for i in range(self.sz):\n",
    "            for j in range(i + 1, self.sz):\n",
    "                if self.l[i][j]:\n",
    "                    self.edges.append(Edge.from_indices(i, j, self.dim[1]))\n",
    "\n",
    "        self.E = len(self.edges)\n",
    "\n",
    "    def getEdges(self, from_position):\n",
    "        eList = []\n",
    "        for v in range(0, self.sz):\n",
    "            if self.l[from_position.to_index(self.dim[1])][v] == 1:\n",
    "                eList.append(NetworkPosition.from_index(v, self.dim[1]))\n",
    "\n",
    "        return eList\n",
    "\n",
    "    def printNet(self):\n",
    "        print(\"|V| = \" + str(self.sz) + \"; |E| = \" + str(self.E))\n",
    "        for u in range(self.sz):\n",
    "            at = NetworkPosition.from_index(u, self.dim[1])\n",
    "            print(f\"{at}: \", end=\"\")\n",
    "            lst = self.getEdges(at)\n",
    "            for network_position in lst:\n",
    "                print(f\" {network_position}\", end=\"\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Network(5, 5, \"Lattice\")\n",
    "net1.generate()\n",
    "# net1.printNet()\n",
    "assert net1.E == 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Network(5, 5, \"Graph\", density=0.25)\n",
    "net2.generate()\n",
    "# net2.printNet()\n",
    "assert net2.E == 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = Network(5, 5, \"CLattice\", density=0.04, spread=5)\n",
    "net3.generate()\n",
    "# net3.printNet()\n",
    "assert net3.E == 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorPlayer(Player):\n",
    "    next_id = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = SimulatorPlayer.next_id\n",
    "        SimulatorPlayer.next_id += 1\n",
    "        super().__init__(None, None)\n",
    "\n",
    "    def init(self, neighbors, player):\n",
    "        if DEBUG:\n",
    "            print(f\"Initializing player {self.id}\")\n",
    "\n",
    "        self.add_neighbors(neighbors)\n",
    "        self.history = player.history\n",
    "        self.strategy = player.strategy\n",
    "        self.strategy_switcher = player.strategy_switcher\n",
    "        self.set_credit(player.credit)\n",
    "\n",
    "    def play(self, opponent):\n",
    "        return super().play(opponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, n, m, pm):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.payoff_matrix = pm\n",
    "        self.population = []\n",
    "        self.cooperation_percentage = []\n",
    "        self.status_matrix = [\n",
    "            [False for _ in range(m)] for _ in range(n)\n",
    "        ]  # to store if self.grid[i,j] is dead or alive\n",
    "\n",
    "    def init_network(self, ntype=\"Lattice\", density=0.0, spread=0.0):\n",
    "        self.network = Network(self.n, self.m, ntype, density, spread)\n",
    "        self.network.generate()\n",
    "\n",
    "    def init_grid(self):\n",
    "        self.grid = []\n",
    "        for i in range(self.n):\n",
    "            self.grid.append([])\n",
    "            for j in range(self.m):\n",
    "                self.grid[i].append(SimulatorPlayer())\n",
    "        self.pairs = [(self.grid[edge.x1][edge.y1], self.grid[edge.x2][edge.y2]) for edge in self.network.edges]\n",
    "\n",
    "    def set_player(self, i, j, player):\n",
    "        ngbr_list = self.network.getEdges(NetworkPosition(i, j))\n",
    "        ngbrs = [self.grid[network_position.x][network_position.y] for network_position in ngbr_list]\n",
    "        self.grid[i][j].init(ngbrs, player)\n",
    "\n",
    "    def match(self, p1: SimulatorPlayer, p2: SimulatorPlayer):\n",
    "        if p1.is_dead() or p2.is_dead():\n",
    "            if DEBUG:\n",
    "                print(f\"P1 is dead: {p1.is_dead()}, P2 is dead: {p2.is_dead()}\")\n",
    "            return None\n",
    "        move1 = p1.play(p2)\n",
    "        move2 = p2.play(p1)\n",
    "\n",
    "        p1.update_tally(p2, move2)\n",
    "        p2.update_tally(p1, move1)\n",
    "\n",
    "        p1.check_should_switch_strategy(p2)\n",
    "        p2.check_should_switch_strategy(p1)\n",
    "\n",
    "        score1, score2 = self.payoff_matrix[move1][move2]\n",
    "\n",
    "        p1.update_credit(score1)\n",
    "        p2.update_credit(score2)\n",
    "\n",
    "        return score1, score2\n",
    "\n",
    "    def round(self):\n",
    "        scores = [[0 for _ in range(self.m)] for _ in range(self.n)]\n",
    "        pair_indices = list(range(len(self.pairs)))\n",
    "        random.shuffle(pair_indices)\n",
    "        for i in pair_indices:\n",
    "            pair = self.pairs[i]\n",
    "            edge = self.network.edges[i]\n",
    "            match_scores = self.match(pair[0], pair[1])\n",
    "            if match_scores is None:\n",
    "                continue\n",
    "            score1, score2 = match_scores\n",
    "            scores[edge.x1][edge.y1] += score1\n",
    "            scores[edge.x2][edge.y2] += score2\n",
    "        return scores\n",
    "\n",
    "    def simulate(self, n_rounds=1, ask_status=False, ask_credits=False):\n",
    "        scores_history = []\n",
    "        status_matrices = []\n",
    "        status_matrices.append(copy.deepcopy(self.status_matrix))\n",
    "        credit_matrices = np.zeros((n_rounds, self.m, self.n))\n",
    "        for _ in range(n_rounds):\n",
    "            scores = self.round()\n",
    "            scores_history.append(scores)\n",
    "            self.population.append(self.count_strategies())\n",
    "            self.update_status()\n",
    "            status_matrices.append(copy.deepcopy(self.status_matrix))\n",
    "            # TODO: This should have looped over self.n first since that's what we do everywhere...\n",
    "            for i in range(self.m):\n",
    "                for j in range(self.n):\n",
    "                    # Here we need to flip the indices of grid because we are looping over self.m first\n",
    "                    credit_matrices[_][i][j] = self.grid[j][i].check_credit()\n",
    "\n",
    "        if ask_status:\n",
    "            return status_matrices, scores_history\n",
    "        elif ask_credits:\n",
    "            return credit_matrices\n",
    "        else:\n",
    "            return scores_history\n",
    "\n",
    "    def count_strategies(self, strategy_classes=Strategy.__subclasses__()):\n",
    "        strategy_names = [agent.strategy.__class__.__name__ for grid_line in self.grid for agent in grid_line]\n",
    "        strategy_counts = {name: strategy_names.count(name) for name in [cls.__name__ for cls in strategy_classes]}\n",
    "        return strategy_counts\n",
    "\n",
    "    # New function, to update status_matrix\n",
    "    def update_status(self):\n",
    "        # Update the status of each element in the matrix\n",
    "        for i in range(len(self.status_matrix)):\n",
    "            for j in range(len(self.status_matrix[i])):\n",
    "                self.status_matrix[i][j] = self.grid[i][j].is_dead()\n",
    "\n",
    "    def update_cooperation_rate(self, n_rounds):\n",
    "        for round in range(n_rounds):\n",
    "            round_strings = []\n",
    "\n",
    "            for i in range(self.n):\n",
    "                for j in range(self.m):\n",
    "                    d = len(self.grid[i][j].history) / n_rounds\n",
    "                    start = int(round * d)\n",
    "                    end = int(start + d)\n",
    "                    player_string = self.grid[i][j].history[start:end]\n",
    "                    round_strings += player_string\n",
    "\n",
    "            self.cooperation_percentage.append(round_strings)\n",
    "\n",
    "    def plot_cooperation(self, n_rounds, save_path=None, no_plot=False):\n",
    "        self.update_cooperation_rate(n_rounds)\n",
    "        # Step 1: Calculate percentages per time step\n",
    "        percentages = []\n",
    "        for sublist in self.cooperation_percentage:\n",
    "            count_C = sublist.count(\"C\")\n",
    "            total_count = len(sublist)\n",
    "            percentage_C = count_C / total_count if total_count > 0 else 0\n",
    "            percentages.append(percentage_C)\n",
    "\n",
    "        if not no_plot:\n",
    "            # Step 2: Plotting\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(percentages)\n",
    "\n",
    "            plt.xlabel(\"Virtual Time (rounds)\")\n",
    "            plt.ylabel(\"Percentage of Cooperation\")\n",
    "            plt.title(\"Percentage of Cooperation Over Time\")\n",
    "            # plt.xticks(range(len(self.cooperation_percentage)))\n",
    "            plt.grid(True)\n",
    "\n",
    "            if save_path:\n",
    "                create_dirpath(save_path)\n",
    "                plt.savefig(save_path)\n",
    "\n",
    "            plt.show()\n",
    "        return percentages\n",
    "\n",
    "    def plot_evolution(self, save_path=None):\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(self.population)\n",
    "\n",
    "        # Filter out columns (strategies) where all values are zero\n",
    "        df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for column in df.columns:\n",
    "            plt.plot(df[column], label=column)\n",
    "            # plt.plot(df.index, df[column], marker='o', label=column)\n",
    "\n",
    "        plt.xlabel(\"Virtual Time (rounds)\")\n",
    "        plt.ylabel(\"Strategy Value\")\n",
    "        plt.title(\"Evolution of Strategies Over Time\")\n",
    "        # plt.xticks(range(len(df)))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        if save_path:\n",
    "            create_dirpath(save_path)\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "        plt.show()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_of_strats = Strategy.__subclasses__()\n",
    "pool_of_strats.remove(DeadStrategy)\n",
    "# NOTE: Some StrategySwitchers have default parameters we could play around with.\n",
    "pool_of_switchers = StrategySwitcher.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "\n",
    "50-50 AllC and AllD strats randomly distributed. AllD players have SoftMajor switcher, AllC players have a random chance $p$ of having NOPSiwtcher.\n",
    "\n",
    "Result: for $p >= 0.1$, all players eventually adopt AllC strategy.\n",
    "\n",
    "Interpretation: small number of pure cooperative players lead to stable cooperation starting from symmetry 50-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment scale\n",
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "insist_percent = np.arange(0, 1 + 0.01, 0.05)\n",
    "cooperate_dominance = np.zeros(len(insist_percent))\n",
    "for k, p in enumerate(insist_percent):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            if chosen_strategy == AlwaysCooperateStrategy and random.random() < p:\n",
    "                chosen_switcher = NOPSwitcher\n",
    "            else:\n",
    "                chosen_switcher = SoftMajor\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher()))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment1/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment1/evolution.png\")\n",
    "\n",
    "plt.plot(insist_percent, cooperate_dominance)\n",
    "plt.xlabel(\"Percentage of pure Cooperative Players\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.title(\"Small number of pure cooperative players can invade all\")\n",
    "plt.savefig(\"results/experiment1/insist_percent_v_cooperate_dominance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "50-50 AllC and AllD strats randomly distributed. All players have SoftMajor switcher.\n",
    "\n",
    "Result: eventually the numbers of AllC and AllD players saturate, around values around 0.5 (this depends on the distribution) -> so is the cooperation rate.\n",
    "\n",
    "Interpretation: everyone mimics their neighbors will lead to random equilibrium around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 20\n",
    "cooperate_dominance = np.zeros(iterations)  # The percentage of allC in each and every iteration\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            chosen_switcher = SoftMajor\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher()))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment2/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment2/evolution.png\")\n",
    "\n",
    "plt.scatter(np.arange(0, len(cooperate_dominance), 1), cooperate_dominance)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.title(\"SoftMajor leads to random equilibrium around 50-50\")\n",
    "plt.savefig(\"results/experiment2/cooperative_players_at_equilibrium.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_points(grid_size, N):\n",
    "    points = set()\n",
    "\n",
    "    while len(points) < N:\n",
    "        x = random.randint(0, grid_size - 1)\n",
    "        y = random.randint(0, grid_size - 1)\n",
    "        points.add((x, y))\n",
    "\n",
    "    return list(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3a\n",
    "\n",
    "Start with all players cooperating (allC) except a few n_defect random allD. All players adopt CooperateUntilNDefect switcher.\n",
    "\n",
    "Interpretation: A population with cynical meta-strategy (switcher) will lead to instable cooperative behavior: only takes some allD to invade all.\n",
    "\n",
    "Expected result:\n",
    "\n",
    "1) For non-zero n_defect, eventually, most if not all players will be allD\n",
    "2) As we increase n_defect (initial number of allD players), it will take fewer rounds to reach allD population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 20\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "# We sprinkle some AllD randomly on lattice:\n",
    "n_defect = 15\n",
    "AllD_players_list = generate_random_points(grid_size, n_defect)\n",
    "\n",
    "iterations = 1\n",
    "cooperate_dominance = np.zeros(iterations)  # The percentage of allC in each and every iteration\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in AllD_players_list:\n",
    "                chosen_strategy = AlwaysDefectStrategy\n",
    "            else:\n",
    "                chosen_strategy = AlwaysCooperateStrategy\n",
    "            chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "            # TODO: Vary the N\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment3a/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment3a/evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3b\n",
    "We repeat the above setup, but only 1 defective player x, run over many iterations, each with a different location for X. Goal: investigate the effect of X's location on the number of steps needed for cooperation collapse (coop percentage drops below 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 20\n",
    "num_rounds = 50\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "collapse_points = np.zeros((grid_size, grid_size))\n",
    "for m in range(grid_size):\n",
    "    for n in range(grid_size):\n",
    "        current_point = (m, n)\n",
    "        s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "        s.init_network(\"Lattice\")\n",
    "        s.init_grid()\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if (i, j) == current_point:\n",
    "                    chosen_strategy = AlwaysDefectStrategy\n",
    "                else:\n",
    "                    chosen_strategy = AlwaysCooperateStrategy\n",
    "                chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "                # TODO: Vary the N\n",
    "                s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "        s.simulate(n_rounds=num_rounds)\n",
    "        # coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\n",
    "        percentage_list = s.plot_cooperation(num_rounds, no_plot=True)\n",
    "        collapse_step = next((i for i, x in enumerate(percentage_list) if x < 0.1), None)\n",
    "        collapse_points[m][n] = collapse_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.imshow(collapse_points, cmap=\"hot\", interpolation=\"nearest\")\n",
    "\n",
    "# Add a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Defector collapse index\")\n",
    "create_dirpath(\"results/experiment3b/defector_collapse_index.png\")\n",
    "plt.savefig(\"results/experiment3b/defector_collapse_index.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3c\n",
    "We run the setups with various numbers of defects (each with many iterations to average over) to find the number of steps (on average) it takes until cooperation collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 20\n",
    "num_rounds = 30\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "n_defect = 4\n",
    "densities = [0.02, 0.04, 0.06, 0.08, 0.1]\n",
    "collapse_points = np.zeros(len(densities))  # array to store average collapse points for different defect_num\n",
    "\n",
    "iteration_num = 20\n",
    "for _, density in enumerate(densities):\n",
    "    # to store all collapse_step over iterations to be averaged over\n",
    "    temp_array = np.zeros(iteration_num)\n",
    "    for k in range(iteration_num):\n",
    "        AllD_players_list = generate_random_points(grid_size, n_defect)\n",
    "        s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "        s.init_network(\"CLattice\", density=density, spread=6)\n",
    "        s.init_grid()\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if (i, j) in AllD_players_list:\n",
    "                    chosen_strategy = AlwaysDefectStrategy\n",
    "                else:\n",
    "                    chosen_strategy = AlwaysCooperateStrategy\n",
    "                chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "                # TODO: Vary the N\n",
    "                s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "        s.simulate(n_rounds=num_rounds)\n",
    "        # coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\n",
    "        percentage_list = s.plot_cooperation(num_rounds, no_plot=True)\n",
    "        collapse_step = next((i for i, x in enumerate(percentage_list) if x < 0.1), None)\n",
    "        temp_array[k] = collapse_step\n",
    "\n",
    "    collapse_points[_] = np.mean(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Define the exponential function\n",
    "def exp_decay_func(x, a, b):\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "\n",
    "defect_num = np.array(defect_num)\n",
    "# Perform the curve fitting\n",
    "params, _ = curve_fit(exp_decay_func, defect_num, collapse_points)\n",
    "a, b = params[0], params[1]\n",
    "\n",
    "# Generate a denser set of x-values for the smoother curve\n",
    "x_dense = np.linspace(defect_num.min(), defect_num.max(), 500)\n",
    "\n",
    "# Calculate the fitted y-values for the denser x-values\n",
    "fitted_y_dense = exp_decay_func(x_dense, a, b)\n",
    "\n",
    "# Calculate residuals and the standard deviation\n",
    "residuals = collapse_points - exp_decay_func(defect_num, a, b)\n",
    "std_dev = np.std(residuals)\n",
    "\n",
    "# Create the plot\n",
    "plt.errorbar(defect_num, collapse_points, yerr=std_dev, fmt=\"o\", label=\"Original Data\", ecolor=\"lightgray\", capsize=5)\n",
    "plt.plot(x_dense, fitted_y_dense, label=\"Fitted Exponential Curve\", color=\"red\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Number of defects\")\n",
    "plt.ylabel(\"Average collapse index\")\n",
    "plt.title(\"Average collapse index vs number of defects randomly distributed\")\n",
    "plt.legend()\n",
    "\n",
    "create_dirpath(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "plt.savefig(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: credit system\n",
    "\n",
    "Start with 50-50 allC, allD in terms of strategies. For switchers we pick equal number of each. Give each player the same number of credits initially.\n",
    "\n",
    "1) We plot number of non-debters (survivors) against time to see if some switchers cannot survive.\n",
    "2) Repeat for different pay-off matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that evenly assigns players to switcher types via lattice location\n",
    "# input N: number of switchers\n",
    "# return lookup_table: dictionary to tell which switcher type (i,j) belongs to (outcome indexed by pool_of_switchers)\n",
    "def assign_switchers(grid_size, N):\n",
    "    total_vertices = grid_size**2\n",
    "    approx_size = total_vertices // N\n",
    "    extra = total_vertices % N\n",
    "\n",
    "    vertices_sets = [set() for _ in range(N)]\n",
    "    lookup_table = {}\n",
    "    current_set = 0\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            vertices_sets[current_set].add((i, j))\n",
    "            lookup_table[(i, j)] = current_set\n",
    "            if len(vertices_sets[current_set]) >= approx_size + (current_set < extra):\n",
    "                current_set += 1\n",
    "\n",
    "    return vertices_sets, lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 10\n",
    "CHOSEN_PAYOFF_MATRIX = NEGATIVE_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 1\n",
    "\n",
    "sets, players_switchers = assign_switchers(grid_size, len(pool_of_switchers))\n",
    "\n",
    "init_credit = 15  # initial credit per player\n",
    "\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            chosen_switcher = pool_of_switchers[players_switchers[(i, j)]]\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(payoff_matrix=CHOSEN_PAYOFF_MATRIX), init_credit))\n",
    "\n",
    "    status_matrices, _ = s.simulate(n_rounds=num_rounds, ask_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# visualize dead (blue) or alive (red) at a time step (has 1 element more than number of time steps to account for initial status)\n",
    "def visualize_boolean_matrix(matrix, save_path=None):\n",
    "    # Create a custom colormap for True (black) and False (white)\n",
    "    cmap = mcolors.ListedColormap([\"black\", \"white\"])\n",
    "\n",
    "    # Convert the boolean matrix to integers (True=0, False=1)\n",
    "    int_matrix = np.where(matrix, 0, 1)\n",
    "\n",
    "    # Plot the matrix with the custom colormap\n",
    "    plt.imshow(int_matrix, cmap=cmap, interpolation=\"none\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_path:\n",
    "        create_dirpath(save_path)\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO: Why status_matrices[2]?\n",
    "visualize_boolean_matrix(status_matrices[2], save_path=\"results/experiment4/status_matrices.png\")\n",
    "# print(status_matrices[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that counts dead/alive players of each switcher type for a status_matrix at a time step\n",
    "def count_true_false(status_matrix, lookup, N):\n",
    "    # Initialize counters for each set\n",
    "    counters = {i: {\"True\": 0, \"False\": 0} for i in range(N)}\n",
    "\n",
    "    # Iterate over the status_matrix\n",
    "    for i in range(len(status_matrix)):\n",
    "        for j in range(len(status_matrix[i])):\n",
    "            set_index = lookup[(i, j)]\n",
    "            if status_matrix[i][j]:\n",
    "                counters[set_index][\"True\"] += 1\n",
    "            else:\n",
    "                counters[set_index][\"False\"] += 1\n",
    "\n",
    "    return counters\n",
    "\n",
    "\n",
    "# Function that counts dead/alive players of each switcher type for all time step status_matrix, i.e. status_matrices\n",
    "def compute_counters_for_all_matrices(status_matrices, lookup, N):\n",
    "    all_counters = []\n",
    "    for status_matrix in status_matrices:\n",
    "        counters = count_true_false(status_matrix, lookup, N)\n",
    "        all_counters.append(counters)\n",
    "    return all_counters\n",
    "\n",
    "\n",
    "counters_end = count_true_false(status_matrices[-1], players_switchers, len(pool_of_switchers))\n",
    "counters_beg = count_true_false(status_matrices[0], players_switchers, len(pool_of_switchers))\n",
    "\n",
    "\n",
    "# SOME QUICK CHECK\n",
    "print(\"Current payoff matrix:\")\n",
    "print(CHOSEN_PAYOFF_MATRIX)\n",
    "# Output the counts for each switcher at the beginning and the end\n",
    "print(\"\\nBegin:\")\n",
    "for set_index, counts in counters_beg.items():\n",
    "    print(f\"Switcher {set_index + 1}: Dead = {counts['True']}, Alive = {counts['False']}\")\n",
    "print(\"\\nFinal:\")\n",
    "for set_index, counts in counters_end.items():\n",
    "    print(f\"Switcher {set_index + 1}: Dead = {counts['True']}, Alive = {counts['False']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counters = compute_counters_for_all_matrices(status_matrices, players_switchers, len(pool_of_switchers))\n",
    "\n",
    "# Preparing data for plotting\n",
    "true_counts = {i: [] for i in range(len(pool_of_switchers))}\n",
    "for counters in all_counters:\n",
    "    for set_index in range(len(pool_of_switchers)):\n",
    "        true_counts[set_index].append(counters[set_index][\"True\"])\n",
    "\n",
    "# Plotting\n",
    "for set_index, counts in true_counts.items():\n",
    "    plt.plot(counts, label=str(pool_of_switchers[set_index].__name__))\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Number of Dead Players\")\n",
    "plt.title(\"Dead Players Over Time for Each Switcher\")\n",
    "plt.legend()\n",
    "create_dirpath(\"results/experiment4/dead_players_over_time.png\")\n",
    "plt.savefig(\"results/experiment4/dead_players_over_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5\n",
    "50-50 allC and allD starting out similarly to exp 1. Instead of mimicking their neighbors, players use Bayesian probability based on opponent's history to adapt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment scale\n",
    "grid_size = 50\n",
    "num_rounds = 100\n",
    "CHOSEN_PAYOFF_MATRIX = PAYOFF_MATRIX_FOR_ADAPTIVE\n",
    "\n",
    "# insist_percent = np.arange(0, 1 + 0.01, 0.05)\n",
    "insist_percent = [0.0]\n",
    "cooperate_dominance = np.zeros(len(insist_percent))\n",
    "for k, p in enumerate(insist_percent):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            if chosen_strategy == AlwaysCooperateStrategy and random.random() < p:\n",
    "                chosen_switcher = NOPSwitcher\n",
    "            else:\n",
    "                chosen_switcher = AdaptiveSwitcher\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(payoff_matrix=CHOSEN_PAYOFF_MATRIX)))\n",
    "\n",
    "    s.simulate(n_rounds=num_rounds)\n",
    "    strategy_counts = s.count_strategies()\n",
    "    cooperate_dominance[k] = strategy_counts[\"AlwaysCooperateStrategy\"] / (\n",
    "        strategy_counts[\"AlwaysDefectStrategy\"] + strategy_counts[\"AlwaysCooperateStrategy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_cooperation(num_rounds, save_path=\"results/experiment5/cooperation.png\")\n",
    "dff = s.plot_evolution(save_path=\"results/experiment5/evolution.png\")\n",
    "\n",
    "plt.plot(insist_percent, cooperate_dominance)\n",
    "plt.xlabel(\"Percentage of pure Cooperative Players\")\n",
    "plt.ylabel(\"Percentage of Cooperative players at equilibrium\")\n",
    "plt.savefig(\"results/experiment5/insist_percent_v_cooperate_dominance.png\")\n",
    "plt.title(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6a\n",
    "Experiment 3c but with multiple networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322, 0.9971116816431322]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629, 0.998395378690629]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "[0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126, 0.9978777589134126]\n",
      "[0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364]\n",
      "[0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364]\n",
      "[0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364]\n",
      "[0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364, 0.9972410865874364]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# TODO: Vary the N\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         s\u001b[38;5;241m.\u001b[39mset_player(i, j, Player(chosen_strategy(), chosen_switcher(\u001b[38;5;241m5\u001b[39m)))\n\u001b[0;32m---> 28\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\u001b[39;00m\n\u001b[1;32m     30\u001b[0m percentage_list \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mplot_cooperation(num_rounds, no_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[30], line 74\u001b[0m, in \u001b[0;36mSimulator.simulate\u001b[0;34m(self, n_rounds, ask_status, ask_credits)\u001b[0m\n\u001b[1;32m     72\u001b[0m credit_matrices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_rounds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn))\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_rounds):\n\u001b[0;32m---> 74\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     scores_history\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_strategies())\n",
      "Cell \u001b[0;32mIn[30], line 60\u001b[0m, in \u001b[0;36mSimulator.round\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs[i]\n\u001b[1;32m     59\u001b[0m edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39medges[i]\n\u001b[0;32m---> 60\u001b[0m match_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 40\u001b[0m, in \u001b[0;36mSimulator.match\u001b[0;34m(self, p1, p2)\u001b[0m\n\u001b[1;32m     37\u001b[0m move1 \u001b[38;5;241m=\u001b[39m p1\u001b[38;5;241m.\u001b[39mplay(p2)\n\u001b[1;32m     38\u001b[0m move2 \u001b[38;5;241m=\u001b[39m p2\u001b[38;5;241m.\u001b[39mplay(p1)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_tally\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m p2\u001b[38;5;241m.\u001b[39mupdate_tally(p1, move1)\n\u001b[1;32m     43\u001b[0m p1\u001b[38;5;241m.\u001b[39mcheck_should_switch_strategy(p2)\n",
      "Cell \u001b[0;32mIn[22], line 47\u001b[0m, in \u001b[0;36mPlayer.update_tally\u001b[0;34m(self, opponent, opponent_move)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_tally\u001b[39m(\u001b[38;5;28mself\u001b[39m, opponent, opponent_move):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_tallies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mopponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopponent_move\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbor_histories[opponent\u001b[38;5;241m.\u001b[39mid]\u001b[38;5;241m.\u001b[39mappend(opponent_move)\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mPlayerMoveTally.update\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m      3\u001b[0m cooperations: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m defections: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, move):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m move \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooperations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_size = 20\n",
    "num_rounds = 30\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "densities = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "n_defect = 1\n",
    "collapse_points = np.zeros(len(densities))\n",
    "\n",
    "iteration_num = 20\n",
    "for _, n_density in enumerate(densities):\n",
    "    # to store all collapse_step over iterations to be averaged over\n",
    "    temp_array = np.zeros(iteration_num)\n",
    "    for k in range(iteration_num):\n",
    "        AllD_players_list = generate_random_points(grid_size, n_defect)\n",
    "        s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "        s.init_network(\"CLattice\", density=n_density, spread=6)\n",
    "        s.init_grid()\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if (i, j) in AllD_players_list:\n",
    "                    chosen_strategy = AlwaysDefectStrategy\n",
    "                else:\n",
    "                    chosen_strategy = AlwaysCooperateStrategy\n",
    "                chosen_switcher = CooperateUntilNDefectionsInARow\n",
    "                # TODO: Vary the N\n",
    "                s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(1)))\n",
    "\n",
    "        s.simulate(n_rounds=num_rounds)\n",
    "        # coop_percent_over_iterations.append(s.plot_cooperation(num_rounds,no_plot=False))\n",
    "        percentage_list = s.plot_cooperation(num_rounds, no_plot=True)\n",
    "        print(percentage_list)\n",
    "        collapse_step = next((i for i, x in enumerate(percentage_list) if x < 0.1), None)\n",
    "        temp_array[k] = collapse_step\n",
    "    print(temp_array)\n",
    "    collapse_points[_] = np.mean(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Define the exponential function\n",
    "def exp_decay_func(x, a, b):\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "\n",
    "densities = np.array(densities)\n",
    "# Perform the curve fitting\n",
    "params, _ = curve_fit(exp_decay_func, densities, collapse_points)\n",
    "a, b = params[0], params[1]\n",
    "\n",
    "# Generate a denser set of x-values for the smoother curve\n",
    "x_dense = np.linspace(densities.min(), densities.max(), 500)\n",
    "\n",
    "# Calculate the fitted y-values for the denser x-values\n",
    "fitted_y_dense = exp_decay_func(x_dense, a, b)\n",
    "\n",
    "# Calculate residuals and the standard deviation\n",
    "residuals = collapse_points - exp_decay_func(densities, a, b)\n",
    "std_dev = np.std(residuals)\n",
    "\n",
    "# Create the plot\n",
    "plt.errorbar(densities, collapse_points, yerr=std_dev, fmt=\"o\", label=\"Original Data\", ecolor=\"lightgray\", capsize=5)\n",
    "plt.plot(x_dense, fitted_y_dense, label=\"Fitted Exponential Curve\", color=\"red\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Number of defects\")\n",
    "plt.ylabel(\"Average collapse index\")\n",
    "plt.title(\"Average collapse index vs number of defects randomly distributed\")\n",
    "plt.legend()\n",
    "\n",
    "create_dirpath(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "plt.savefig(\"results/experiment3c/defector_collapse_index_v_defect_num.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(collapse_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing animations\n",
    "create an gif of a grid of credits evolving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_rounds = 10\n",
    "CHOSEN_PAYOFF_MATRIX = TYPICAL_PAYOFF_MATRIX\n",
    "\n",
    "iterations = 1\n",
    "\n",
    "sets, players_switchers = assign_switchers(grid_size, len(pool_of_switchers))\n",
    "\n",
    "init_credit = 0  # initial credit per player\n",
    "\n",
    "for k in range(iterations):\n",
    "    s = Simulator(grid_size, grid_size, pm=CHOSEN_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            chosen_strategy = random.choice([AlwaysCooperateStrategy, AlwaysDefectStrategy])\n",
    "            # chosen_switcher = pool_of_switchers[players_switchers[(i,j)]]\n",
    "            chosen_switcher = NOPSwitcher\n",
    "            s.set_player(i, j, Player(chosen_strategy(), chosen_switcher(), init_credit))\n",
    "\n",
    "    credit_matrices = s.simulate(n_rounds=num_rounds, ask_credits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Example data: a simple 3D numpy array\n",
    "# For the sake of example, let's create a 3D array with random data\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Function to update the plot for each frame\n",
    "def update(frame):\n",
    "    mat.set_data(credit_matrices[frame])\n",
    "    return [mat]\n",
    "\n",
    "\n",
    "# Set up the initial plot\n",
    "fig, ax = plt.subplots()\n",
    "mat = ax.matshow(credit_matrices[0], cmap=\"viridis\")\n",
    "plt.colorbar(mat)\n",
    "ax.set_title(\"Credit matrix evolution\")\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=num_rounds, interval=200, blit=True)\n",
    "create_dirpath(\"results/animations/credit_matrix_evolution.gif\")\n",
    "ani.save(\"results/animations/lattice_evolution.gif\", writer=\"pillow\", fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CooperateUntilNDefectionsInARow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cooperate_until_n_defections_in_a_row(threshold_n, repeated_list):\n",
    "    print(f\"Testing CooperateUntilNDefectionsInARow (N = {threshold_n})\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), CooperateUntilNDefectionsInARow(threshold_n)))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    threshold_hit, ds_in_a_row = False, 0\n",
    "    for move in repeated_list:\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            ds_in_a_row += 1\n",
    "        else:\n",
    "            ds_in_a_row = 0\n",
    "\n",
    "        if ds_in_a_row >= threshold_n:\n",
    "            threshold_hit = True\n",
    "\n",
    "        if threshold_hit:\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=1,\n",
    "    repeated_list=[\"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=1,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=2,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cooperate_until_n_defections_in_a_row(\n",
    "    threshold_n=3,\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TitForTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tit_for_tat(repeated_list):\n",
    "    print(f\"Testing TitForTat\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), TitForTat()))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    for move in repeated_list:\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tit_for_tat(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\", \"C\", \"C\", \"D\", \"D\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetaliateWithTwoDefections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retaliate_with_two_defections(repeated_list, *, n_retaliations=2):\n",
    "    print(f\"Testing RetaliateWithTwoDefections\")\n",
    "    s = Simulator(n=2, m=1, pm=TYPICAL_PAYOFF_MATRIX)\n",
    "    s.init_network(\"Lattice\")\n",
    "    s.init_grid()\n",
    "    s.set_player(0, 0, Player(AlwaysCooperateStrategy(), RetaliateWithTwoDefections()))\n",
    "    s.set_player(1, 0, Player(ListRepeatedStrategy(repeated_list), NOPSwitcher()))\n",
    "\n",
    "    expected_strategies = []\n",
    "    n_defections_left = 0\n",
    "    for move in repeated_list:\n",
    "        assert n_defections_left >= 0\n",
    "        assert move in [\"C\", \"D\"]\n",
    "\n",
    "        if move == \"D\":\n",
    "            n_defections_left += n_retaliations\n",
    "\n",
    "        if n_defections_left > 0:\n",
    "            n_defections_left -= 1\n",
    "            expected_strategies.append(AlwaysDefectStrategy)\n",
    "        else:\n",
    "            expected_strategies.append(AlwaysCooperateStrategy)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\n",
    "            f\"Expected strategy for repeated list {repeated_list}: {[expected_strategy.__name__ for expected_strategy in expected_strategies]}\"\n",
    "        )\n",
    "\n",
    "    assert s.grid[0][0].strategy.__class__ == AlwaysCooperateStrategy\n",
    "\n",
    "    for expected_strategy in expected_strategies:\n",
    "        s.simulate(n_rounds=1)\n",
    "        assert s.grid[0][0].strategy.__class__ == expected_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"C\", \"C\", \"C\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"D\", \"D\", \"C\", \"C\", \"C\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retaliate_with_two_defections(\n",
    "    repeated_list=[\"C\", \"C\", \"D\", \"D\", \"C\", \"D\", \"C\", \"C\", \"D\", \"D\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMajor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaptiveSwitcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
