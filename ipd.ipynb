{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def move(self, own_history, opponent_history):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C unless opponent's last move was D\n",
    "class TitForTatStrategy(Strategy):\n",
    "    def move(self, own_history, opponent_history):\n",
    "        if not opponent_history or opponent_history[-1] == 'C':\n",
    "            move = 'C'\n",
    "        else:\n",
    "            move = 'D'\n",
    "\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naively faithful player (always chooses C)\n",
    "class AlwaysCooperateStrategy(Strategy):\n",
    "    def move(self, own_history, opponent_history):\n",
    "        move = 'C'\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always chooses D\n",
    "class AlwaysDefectStrategy(Strategy):\n",
    "    def move(self, own_history, opponent_history):\n",
    "        move = 'D'\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternating choices between C and D\n",
    "class AlternatingStrategy(Strategy):\n",
    "    def move(self, own_history, opponent_history):\n",
    "        if not own_history or own_history[-1] == 'D':\n",
    "            move = 'C'\n",
    "        else:\n",
    "            move = 'D'\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special class of adaptive players who weighs the expected score for each decision (over opponent's history)\n",
    "class AdaptiveStrategy(Strategy):\n",
    "    def move(self, own_history, opponent_history):\n",
    "        # percentage of cooperative decisions in opponent's history\n",
    "        if len(opponent_history) != 0:\n",
    "            opponent_fidelity = opponent_history.count('C')/len(opponent_history)\n",
    "        else:\n",
    "            opponent_fidelity = 1 # assume the best in people\n",
    "        reward_C = opponent_fidelity*3 + (1-opponent_fidelity)*0\n",
    "        reward_D = opponent_fidelity*5 + (1-opponent_fidelity)*1\n",
    "\n",
    "        if reward_C > reward_D:\n",
    "            move = 'C'\n",
    "        else:\n",
    "            move = 'D'\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Grudger(Player):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.has_been_betrayed = False\n",
    "\n",
    "#     def move(self, opponent_history):\n",
    "#         # If the Grudger has never encountered a defect or if the opponent's history is empty\n",
    "#         if not self.has_been_betrayed or not opponent_history:\n",
    "#             if 'D' in opponent_history:\n",
    "#                 self.has_been_betrayed = True\n",
    "#                 move = 'D'\n",
    "#             else:\n",
    "#                 move = 'C'\n",
    "#         else:\n",
    "#             # Defect indefinitely after encountering a betrayal\n",
    "#             move = 'D'\n",
    "#         self.update_history(move)\n",
    "#         return move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Switchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategySwitcher(ABC):\n",
    "    @abstractmethod\n",
    "    def check(self, agent, opponent_history):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOPSwitcher(StrategySwitcher):\n",
    "    def check(self, agent, opponent_history):\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperateUntilDefection(StrategySwitcher):\n",
    "    def check(self, agent, opponent_history):\n",
    "        assert agent.strategy.__class__.__name__ in [\"AlwaysCooperateStrategy\", \"AlwaysDefectStrategy\"]\n",
    "\n",
    "        if agent.strategy.__class__.__name__ == \"AlwaysCooperateStrategy\" and opponent_history and opponent_history[-1] == \"D\":\n",
    "            return True, AlwaysDefectStrategy()\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic class for any Player (next block we shall define inherited classes with specific strategies)\n",
    "class Player:\n",
    "    def __init__(self, strategy, strategy_switcher):\n",
    "        self.history = []\n",
    "        self.strategy = strategy\n",
    "        self.strategy_switcher = strategy_switcher\n",
    "\n",
    "    def play(self, opponent_history):\n",
    "        should_switch_strategy, next_strategy = self.strategy_switcher.check(self, opponent_history)\n",
    "        if should_switch_strategy:\n",
    "            self.switch_strategy(next_strategy)\n",
    "\n",
    "        decision = self.strategy.move(self.history, opponent_history)\n",
    "        self.update_history(decision)\n",
    "        return decision\n",
    "\n",
    "    def update_history(self, own_move):\n",
    "        self.history.append(own_move)\n",
    "\n",
    "    def latest_move(self):\n",
    "        return self.history[-1]\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "    def switch_strategy(self, new_strategy):\n",
    "        self.strategy = new_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a typical Prisoner's Dilemma payoff matrix\n",
    "PAYOFF_MATRIX = {\n",
    "    'C': {'C': (3, 3), 'D': (0, 5)},\n",
    "    'D': {'C': (5, 0), 'D': (1, 1)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that lets player1 and player2 play N rounds\n",
    "def play_game(player1, player2, N):\n",
    "    for _ in range(N):\n",
    "        player1.play(player2.history)  # Player1 decides based on player2's history\n",
    "        player2.play(player1.history)  # Player2 decides based on player1's history\n",
    "\n",
    "    return player1.history, player2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute scores given histories of two players\n",
    "def compute_scores(history1, history2, payoff_matrix):\n",
    "    scores1 = []\n",
    "    scores2 = []\n",
    "\n",
    "    for move1, move2 in zip(history1, history2):\n",
    "        score1, score2 = payoff_matrix[move1][move2]\n",
    "        scores1.append(score1)\n",
    "        scores2.append(score2)\n",
    "\n",
    "    total_score1 = sum(scores1)\n",
    "    total_score2 = sum(scores2)\n",
    "\n",
    "    return scores1, scores2, total_score1, total_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that picks a (different) opponent at random on the lattice\n",
    "def pick_random_opponent(i, j, N):\n",
    "    while True:\n",
    "        opponent_i = random.randint(0, N-1)\n",
    "        opponent_j = random.randint(0, N-1)\n",
    "        if (opponent_i, opponent_j) != (i, j):  # Ensure the opponent is not the same player\n",
    "            return opponent_i, opponent_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate players on a lattice\n",
    "N = 100 # Lattice size\n",
    "lattice = [[None for _ in range(N)] for _ in range(N)]\n",
    "\n",
    "# sprinkle in some special players (adaptive)\n",
    "m = 20\n",
    "special_agents = np.zeros(N * N)\n",
    "special_agents[:m] = 1\n",
    "np.random.shuffle(special_agents)\n",
    "special_agents = special_agents.reshape(N, N)\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if (special_agents[i][j] == 0):\n",
    "            lattice[i][j] = Player(AlternatingStrategy(), NOPSwitcher())\n",
    "        else:\n",
    "            lattice[i][j] = Player(AdaptiveStrategy(), NOPSwitcher())\n",
    "\n",
    "# Let all players each play with (N^2-1) others at random\n",
    "game_num = 2\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        opponent_i, opponent_j = pick_random_opponent(i, j, N)\n",
    "        player = lattice[i][j]\n",
    "        opponent = lattice[opponent_i][opponent_j]\n",
    "        play_game(player, opponent, game_num)\n",
    "\n",
    "\n",
    "# After all games are played, record all history lists into array: data\n",
    "data = np.zeros((game_num*(N**2-1), N, N), dtype=int)  # Initialize data array\n",
    "for j in range(N):\n",
    "    for k in range(N):\n",
    "        player = lattice[j][k]\n",
    "        # print(len(player.history))\n",
    "        decisions = [1 if move == 'C' else -1 for move in player.history]\n",
    "        data[:len(decisions), j, k] = decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block of code for visualization (export a .gif for now)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "\n",
    "sums_along_first_axis = np.sum(np.abs(data), axis=(1,2))\n",
    "last_nonzero_slice = np.max(np.nonzero(sums_along_first_axis))\n",
    "data_truncate = data[:last_nonzero_slice + 1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('off')\n",
    "\n",
    "# Setting up the colormap - you can choose your own colors\n",
    "cmap = plt.get_cmap(\"RdYlBu\")\n",
    "norm = plt.Normalize(-1, 1)\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    ax.imshow(data_truncate[frame], cmap=cmap, norm=norm)\n",
    "    ax.set_title(f\"Time step: {frame}\")\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=data_truncate.shape[0], repeat=True)\n",
    "# plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap))\n",
    "\n",
    "# Save as GIF\n",
    "ani.save(\"animation.gif\", writer=PillowWriter(fps=1))\n",
    "\n",
    "# Show the animation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count number of players of each strategy\n",
    "def count_strategies(agent_list, strategy_classes):\n",
    "    strategy_counts = {name: 0 for name in [cls.__name__ for cls in strategy_classes]}\n",
    "\n",
    "    for agent in agent_list:\n",
    "        for strategy_class in strategy_classes:\n",
    "            if isinstance(agent.strategy, strategy_class):\n",
    "                strategy_counts[strategy_class.__name__] += 1\n",
    "                break\n",
    "\n",
    "    return strategy_counts\n",
    "\n",
    "# Flatten the lattice and count:\n",
    "strategy_classes = Strategy.__subclasses__()\n",
    "agents = [item for sublist in lattice for item in sublist]\n",
    "strategy_distribution = count_strategies(agents, strategy_classes)\n",
    "print(strategy_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics, only applicable after define switching (with conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test CooperateUntilDefection\")\n",
    "lattice = [Player(AlwaysCooperateStrategy(), CooperateUntilDefection()), Player(AlwaysDefectStrategy(), NOPSwitcher())]\n",
    "assert lattice[0].strategy.__class__.__name__ == \"AlwaysCooperateStrategy\"\n",
    "play_game(lattice[0], lattice[1], 2)\n",
    "assert lattice[0].strategy.__class__.__name__ == \"AlwaysDefectStrategy\"\n",
    "print(\"Passed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
